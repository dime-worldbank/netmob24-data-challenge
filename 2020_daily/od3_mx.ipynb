{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac80492-7321-4716-9eb6-480a39e423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%config SqlMagic.autolimit=0\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaylimit=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb53c70-0bcd-42db-b993-22c1e27621c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @cuebiq/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql trino://localhost:9090/cuebiq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb085d33-6d88-45c7-8157-b6117b60533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-geohash in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.8.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9ead77-7643-4b96-833e-1727f453930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geohash\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bd797a-04e3-4191-9761-96e660fd396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine\n",
    "from trino.dbapi import connect \n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d583b13b-220f-4219-be2f-439cf2c1c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_tj_table = f\"{schema_name['cda']}.trajectory_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f56262-6bce-45d7-8ce8-5c1b8e423558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'od_matrix20'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb2a144-af0c-4e66-97e7-20ac1eacc786",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 14:43:51,251 - INFO - Executing SQL query for date 20190101\n",
      "2024-06-17 14:44:01,930 - INFO - Inserted data into table od_mx_20190101_agg3_10\n",
      "2024-06-17 14:44:21,347 - INFO - Executing SQL query for date 20190102\n",
      "2024-06-17 14:44:34,315 - INFO - Inserted data into table od_mx_20190102_agg3_10\n",
      "2024-06-17 14:44:54,314 - INFO - Executing SQL query for date 20190103\n",
      "2024-06-17 14:45:07,753 - INFO - Inserted data into table od_mx_20190103_agg3_10\n",
      "2024-06-17 14:45:30,474 - INFO - Executing SQL query for date 20190104\n",
      "2024-06-17 14:45:45,028 - INFO - Inserted data into table od_mx_20190104_agg3_10\n",
      "2024-06-17 14:46:07,202 - INFO - Executing SQL query for date 20190105\n",
      "2024-06-17 14:46:22,965 - INFO - Inserted data into table od_mx_20190105_agg3_10\n",
      "2024-06-17 14:46:42,762 - INFO - Executing SQL query for date 20190106\n",
      "2024-06-17 14:46:56,966 - INFO - Inserted data into table od_mx_20190106_agg3_10\n",
      "2024-06-17 14:47:16,089 - INFO - Executing SQL query for date 20190107\n",
      "2024-06-17 14:47:27,978 - INFO - Inserted data into table od_mx_20190107_agg3_10\n",
      "2024-06-17 14:47:47,392 - INFO - Executing SQL query for date 20190108\n",
      "2024-06-17 14:47:58,748 - INFO - Inserted data into table od_mx_20190108_agg3_10\n",
      "2024-06-17 14:48:17,493 - INFO - Executing SQL query for date 20190109\n",
      "2024-06-17 14:48:28,274 - INFO - Inserted data into table od_mx_20190109_agg3_10\n",
      "2024-06-17 14:48:47,863 - INFO - Executing SQL query for date 20190110\n",
      "2024-06-17 14:48:59,157 - INFO - Inserted data into table od_mx_20190110_agg3_10\n",
      "2024-06-17 14:49:18,777 - INFO - Executing SQL query for date 20190111\n",
      "2024-06-17 14:49:30,850 - INFO - Inserted data into table od_mx_20190111_agg3_10\n",
      "2024-06-17 14:49:49,251 - INFO - Executing SQL query for date 20190112\n",
      "2024-06-17 14:49:59,934 - INFO - Inserted data into table od_mx_20190112_agg3_10\n",
      "2024-06-17 14:50:16,840 - INFO - Executing SQL query for date 20190113\n",
      "2024-06-17 14:50:26,353 - INFO - Inserted data into table od_mx_20190113_agg3_10\n",
      "2024-06-17 14:50:45,219 - INFO - Executing SQL query for date 20190114\n",
      "2024-06-17 14:50:57,503 - INFO - Inserted data into table od_mx_20190114_agg3_10\n",
      "2024-06-17 14:51:19,250 - INFO - Executing SQL query for date 20190115\n",
      "2024-06-17 14:51:33,175 - INFO - Inserted data into table od_mx_20190115_agg3_10\n",
      "2024-06-17 14:51:54,926 - INFO - Executing SQL query for date 20190116\n",
      "2024-06-17 14:52:08,649 - INFO - Inserted data into table od_mx_20190116_agg3_10\n",
      "2024-06-17 14:52:29,510 - INFO - Executing SQL query for date 20190117\n",
      "2024-06-17 14:52:43,941 - INFO - Inserted data into table od_mx_20190117_agg3_10\n",
      "2024-06-17 14:53:08,069 - INFO - Executing SQL query for date 20190118\n",
      "2024-06-17 14:53:23,107 - INFO - Inserted data into table od_mx_20190118_agg3_10\n",
      "2024-06-17 14:53:44,588 - INFO - Executing SQL query for date 20190119\n",
      "2024-06-17 14:53:57,902 - INFO - Inserted data into table od_mx_20190119_agg3_10\n",
      "2024-06-17 14:54:17,371 - INFO - Executing SQL query for date 20190120\n",
      "2024-06-17 14:54:29,435 - INFO - Inserted data into table od_mx_20190120_agg3_10\n",
      "2024-06-17 14:54:51,152 - INFO - Executing SQL query for date 20190121\n",
      "2024-06-17 14:55:05,306 - INFO - Inserted data into table od_mx_20190121_agg3_10\n",
      "2024-06-17 14:55:27,647 - INFO - Executing SQL query for date 20190122\n",
      "2024-06-17 14:55:41,309 - INFO - Inserted data into table od_mx_20190122_agg3_10\n",
      "2024-06-17 14:56:03,646 - INFO - Executing SQL query for date 20190123\n",
      "2024-06-17 14:56:19,334 - INFO - Inserted data into table od_mx_20190123_agg3_10\n",
      "2024-06-17 14:56:45,136 - INFO - Executing SQL query for date 20190124\n",
      "2024-06-17 14:57:00,992 - INFO - Inserted data into table od_mx_20190124_agg3_10\n",
      "2024-06-17 14:57:25,384 - INFO - Executing SQL query for date 20190125\n",
      "2024-06-17 14:57:39,870 - INFO - Inserted data into table od_mx_20190125_agg3_10\n",
      "2024-06-17 14:58:02,167 - INFO - Executing SQL query for date 20190126\n",
      "2024-06-17 14:58:15,841 - INFO - Inserted data into table od_mx_20190126_agg3_10\n",
      "2024-06-17 14:58:33,750 - INFO - Executing SQL query for date 20190127\n",
      "2024-06-17 14:58:44,780 - INFO - Inserted data into table od_mx_20190127_agg3_10\n",
      "2024-06-17 14:59:06,864 - INFO - Executing SQL query for date 20190128\n",
      "2024-06-17 14:59:20,578 - INFO - Inserted data into table od_mx_20190128_agg3_10\n",
      "2024-06-17 14:59:42,255 - INFO - Executing SQL query for date 20190129\n",
      "2024-06-17 14:59:55,597 - INFO - Inserted data into table od_mx_20190129_agg3_10\n",
      "2024-06-17 15:00:18,069 - INFO - Executing SQL query for date 20190130\n",
      "2024-06-17 15:00:33,898 - INFO - Inserted data into table od_mx_20190130_agg3_10\n",
      "2024-06-17 15:01:05,127 - INFO - Executing SQL query for date 20190131\n",
      "2024-06-17 15:01:20,849 - INFO - Inserted data into table od_mx_20190131_agg3_10\n",
      "2024-06-17 15:01:20,851 - INFO - Total processing time: 1066.64 seconds\n"
     ]
    }
   ],
   "source": [
    "# Only Trip >10\n",
    "# Function to process data for a single day\n",
    "def process_day(event_date, country_code, sql_engine):\n",
    "    try:\n",
    "        # Read data from the SQL table\n",
    "        pe_tj_df = sql_engine.read_sql(\n",
    "            f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id,\n",
    "                start_lat,\n",
    "                start_lng,\n",
    "                end_lat,\n",
    "                end_lng,\n",
    "                duration_minutes,\n",
    "                length_meters,\n",
    "                number_of_points\n",
    "            FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "            WHERE \n",
    "                event_date = {event_date}\n",
    "                AND end_country = '{country_code}' \n",
    "                AND start_country = '{country_code}' \n",
    "            \"\"\"\n",
    "        )\n",
    "        logging.info(f\"Executing SQL query for date {event_date}\")\n",
    "\n",
    "        # Encode geohashes\n",
    "        pe_tj_df['start_geohash3'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=3), axis=1)\n",
    "        pe_tj_df['end_geohash3'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=3), axis=1)\n",
    "\n",
    "        # Aggregation\n",
    "        aggregated_df3 = pe_tj_df.groupby(['start_geohash3', 'end_geohash3']).agg({\n",
    "            'cuebiq_id': 'count',\n",
    "            'duration_minutes': ['mean', 'median', 'std'],\n",
    "            'length_meters': ['mean', 'median', 'std'],\n",
    "            'number_of_points': ['mean', 'median', 'std']\n",
    "        }).reset_index()\n",
    "        aggregated_df3.columns = ['start_geohash3', 'end_geohash3', 'trip_count', 'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                                  'm_length_m', 'mdn_length_m', 'sd_length_m', 'm_points_no', 'mdn_points_no', 'sd_points_no']\n",
    "\n",
    "        # Filter aggregated data and reorder columns\n",
    "        filtered_df3= aggregated_df3.loc[aggregated_df3['trip_count'] > 9]\n",
    "        filtered_df3 = filtered_df3[['start_geohash3', 'end_geohash3', 'trip_count', \n",
    "                                     'm_duration_min', 'mdn_duration_min', 'sd_duration_min', 'm_length_m', 'mdn_length_m', 'sd_length_m', \n",
    "                                   'm_points_no', 'mdn_points_no', 'sd_points_no']]\n",
    "        return filtered_df3\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing data for date {event_date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to insert data with retry mechanism\n",
    "def insert_data_with_retry(df, table_name, con, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                con, \n",
    "                index=False, \n",
    "                if_exists=\"append\", \n",
    "                method=\"multi\"\n",
    "            )\n",
    "            logging.info(f\"Inserted data into table {table_name}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(f\"Failed to insert data into table {table_name} after {retries} attempts\")\n",
    "\n",
    "# Main processing loop\n",
    "def process_date_range(start_date, end_date, country_code, sql_engine):\n",
    "    start_time = time.time()  # Record start time before processing loop\n",
    "        \n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        event_date = current_date.strftime('%Y%m%d')\n",
    "        \n",
    "        filtered_df3 = process_day(event_date, country_code, sql_engine)\n",
    "\n",
    "        # Insert data into the database\n",
    "        if not filtered_df3.empty:\n",
    "            table_name = f\"od_{country_code.lower()}_{event_date}_agg3_10\"\n",
    "            insert_data_with_retry(filtered_df3, table_name, con)\n",
    "        else:\n",
    "            logging.info(f\"No data to insert for date {event_date}\")\n",
    "\n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "    end_time = time.time()  # Record end time after processing loop\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Example usage:\n",
    "process_date_range(datetime(2020, 1, 1), datetime(2020, 12, 31), 'MX', sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94494c01-03d4-4b31-85ce-6f36fd7bb4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d433fa-a50b-494b-a38b-46b58be3beca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d005d-a17a-438d-8bfc-376dc0a21776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6de30-64b3-4c6d-acaa-8ff525f5b924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee43d21-4763-4652-923b-09d09794c5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafc639-8253-4d03-b315-b33ca7dab7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e6360-d7e4-48fe-b166-9c137099d22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253cda9c-2691-450a-9a7d-13b00db6a1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066f28b-d721-4c01-bb54-55fdab5ff329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733afc7-6a43-40ae-a7da-a8e0737d03e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0e731-ca45-483d-b5a2-4e84d0425d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087639b0-581b-4dbf-a9a4-d4b6c7c05505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159c211-e0a9-4aa3-8f88-931269922469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20b8d0-be7b-44e6-95a5-ba70650ede5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4db05-2639-4d55-adae-fec758f9c97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150d96e-8311-4268-9172-a6fa7f5ba1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe55a9-be17-4357-862e-c09c797397e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a779f-0b84-40f8-a379-acf4490e1a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
