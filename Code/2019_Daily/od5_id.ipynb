{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac80492-7321-4716-9eb6-480a39e423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%config SqlMagic.autolimit=0\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaylimit=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb53c70-0bcd-42db-b993-22c1e27621c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @cuebiq/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql trino://localhost:9090/cuebiq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb085d33-6d88-45c7-8157-b6117b60533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-geohash in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.8.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9ead77-7643-4b96-833e-1727f453930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geohash\n",
    "from datetime import datetime, timedelta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bd797a-04e3-4191-9761-96e660fd396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine\n",
    "from trino.dbapi import connect \n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d583b13b-220f-4219-be2f-439cf2c1c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_tj_table = f\"{schema_name['cda']}.trajectory_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dfaadf6-a882-4c99-a7ba-5977fdb9031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 22:48:14,158 - INFO - Executing SQL query for date 20190315\n",
      "2024-06-17 22:48:57,903 - INFO - Data inserted into od_in_20190315_agg5_10\n",
      "2024-06-17 22:49:13,831 - INFO - Executing SQL query for date 20190316\n",
      "2024-06-17 22:49:57,069 - INFO - Data inserted into od_in_20190316_agg5_10\n",
      "2024-06-17 22:49:57,070 - INFO - Total processing time: 119.61 seconds\n"
     ]
    }
   ],
   "source": [
    "# test with only bucket no partition\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to process data for a single day\n",
    "def process_day(event_date, country_code, sql_engine):\n",
    "    try:\n",
    "        # Read data from the SQL table\n",
    "        pe_tj_df = sql_engine.read_sql(\n",
    "            f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id,\n",
    "                start_lat,\n",
    "                start_lng,\n",
    "                end_lat,\n",
    "                end_lng,\n",
    "                duration_minutes,\n",
    "                length_meters,\n",
    "                number_of_points\n",
    "            FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "            WHERE \n",
    "                event_date = {event_date}\n",
    "                AND end_country = '{country_code}' \n",
    "                AND start_country = '{country_code}' \n",
    "            \"\"\"\n",
    "        )\n",
    "        logging.info(f\"Executing SQL query for date {event_date}\")\n",
    "        \n",
    "        # Encode geohashes\n",
    "        pe_tj_df['start_geohash5'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=5), axis=1)\n",
    "        pe_tj_df['end_geohash5'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=5), axis=1)\n",
    "\n",
    "        # Add user numbers to the aggregated data\n",
    "        aggregated_df5 = pe_tj_df.groupby(['start_geohash5', 'end_geohash5']).agg({\n",
    "            'cuebiq_id': 'count',\n",
    "            'duration_minutes': ['mean', 'median', 'std'],\n",
    "            'length_meters': ['mean', 'median', 'std'],\n",
    "            'number_of_points': ['mean', 'median', 'std']\n",
    "        }).reset_index()\n",
    "        aggregated_df5.columns = ['start_geohash5', 'end_geohash5', 'trip_count', \n",
    "                                  'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                                  'm_length_m', 'mdn_length_m', 'sd_length_m',\n",
    "                                  'm_points_no', 'mdn_points_no', 'sd_points_no']\n",
    "\n",
    "        # Filter aggregated data\n",
    "        filtered_df5 = aggregated_df5.loc[aggregated_df5['trip_count'] > 9]\n",
    "        return filtered_df5\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing data for date {event_date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to insert data in chunks\n",
    "def insert_data_in_chunks(df, table_name, engine, chunk_size):\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        chunk = df.iloc[start:start + chunk_size]\n",
    "        chunk.to_sql(table_name, engine, index=False, if_exists='append', method='multi')\n",
    "\n",
    "# Main processing loop\n",
    "def process_date_range(start_date, end_date, country_code, sql_engine):\n",
    "    start_time = time.time()  # Record start time before processing loop\n",
    "        \n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        event_date = current_date.strftime('%Y%m%d')\n",
    "        try:\n",
    "            filtered_df5 = process_day(event_date, country_code, sql_engine)\n",
    "\n",
    "            # Create the SQL engine\n",
    "            output_schema_name = \"od_matrix_10\"\n",
    "            final_table_5 = f\"od_{country_code.lower()}_{event_date}_agg5_10\"\n",
    "            con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "            # Create the SQL table with the correct name for 5-level geohash\n",
    "            create_table_query_5 = f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {final_table_5} (\n",
    "                start_geohash5 varchar,\n",
    "                end_geohash5 varchar,\n",
    "                trip_count bigint,\n",
    "                m_duration_min double,\n",
    "                mdn_duration_min double,\n",
    "                sd_duration_min double,\n",
    "                m_length_m double,\n",
    "                mdn_length_m double,\n",
    "                sd_length_m double,\n",
    "                m_points_no double,\n",
    "                mdn_points_no double,\n",
    "                sd_points_no double\n",
    "            )\n",
    "            WITH (\n",
    "              bucketed_by = ARRAY['end_geohash5'],\n",
    "              bucket_count = 30\n",
    "            )\n",
    "            \"\"\"\n",
    "\n",
    "            with con.connect() as connection:\n",
    "                connection.execute(create_table_query_5)\n",
    "                \n",
    "            filtered_df5 = filtered_df5.astype({\n",
    "                'trip_count': 'int'\n",
    "            })\n",
    "            \n",
    "            # Insert data into the table with the correct name\n",
    "            if not filtered_df5.empty:\n",
    "                \n",
    "                insert_data_in_chunks(filtered_df5, final_table_5, con, 500)\n",
    "                logging.info(f\"Data inserted into {final_table_5}\")\n",
    "            else:\n",
    "                logging.info(f\"No data to insert for {final_table_5} for 5-level geohash\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process data for date {event_date}: {e}\")\n",
    "\n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    end_time = time.time()  # Record end time after processing loop\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    \n",
    "process_date_range(datetime(2019, 1, 1), datetime(2019, 12, 31), 'ID', sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08b612-f19e-4f45-b189-5d258aa4876e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738150b3-c8a1-46ec-ac37-c8a8e4b3a978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd762a9-1202-4601-a6f2-9d908a44e107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c59fc9-2b81-4658-af45-69100b9c43ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c003a02-68a9-46b8-8e01-23717c123282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d582c8a-8735-4726-b083-9f148d2b55c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70/249489361.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df5['local_date'] = event_date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_geohash5</th>\n",
       "      <th>end_geohash5</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>m_duration_min</th>\n",
       "      <th>mdn_duration_min</th>\n",
       "      <th>sd_duration_min</th>\n",
       "      <th>m_length_m</th>\n",
       "      <th>mdn_length_m</th>\n",
       "      <th>sd_length_m</th>\n",
       "      <th>m_points_no</th>\n",
       "      <th>mdn_points_no</th>\n",
       "      <th>sd_points_no</th>\n",
       "      <th>local_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qpz6e</td>\n",
       "      <td>qpz6e</td>\n",
       "      <td>42</td>\n",
       "      <td>87.852381</td>\n",
       "      <td>32.208333</td>\n",
       "      <td>168.030579</td>\n",
       "      <td>4676.194708</td>\n",
       "      <td>1523.026116</td>\n",
       "      <td>13531.575806</td>\n",
       "      <td>10.119048</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.381653</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qpz6e</td>\n",
       "      <td>qpz6s</td>\n",
       "      <td>10</td>\n",
       "      <td>43.406667</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>36.721081</td>\n",
       "      <td>3931.408664</td>\n",
       "      <td>3428.999614</td>\n",
       "      <td>2486.709348</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.852926</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qpz6g</td>\n",
       "      <td>qpz6e</td>\n",
       "      <td>10</td>\n",
       "      <td>57.320000</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>58.491738</td>\n",
       "      <td>7226.994729</td>\n",
       "      <td>5089.530602</td>\n",
       "      <td>5321.204434</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.190263</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>qpz6g</td>\n",
       "      <td>qpz6g</td>\n",
       "      <td>21</td>\n",
       "      <td>88.769048</td>\n",
       "      <td>42.916667</td>\n",
       "      <td>111.668216</td>\n",
       "      <td>4799.423202</td>\n",
       "      <td>1268.281055</td>\n",
       "      <td>7019.272456</td>\n",
       "      <td>15.904762</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.158989</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>qpz6s</td>\n",
       "      <td>qpz6s</td>\n",
       "      <td>38</td>\n",
       "      <td>80.742982</td>\n",
       "      <td>32.708333</td>\n",
       "      <td>96.794736</td>\n",
       "      <td>2479.739199</td>\n",
       "      <td>1489.384521</td>\n",
       "      <td>3569.710189</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.214815</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16059</th>\n",
       "      <td>wb2b2</td>\n",
       "      <td>wb2b3</td>\n",
       "      <td>12</td>\n",
       "      <td>103.481944</td>\n",
       "      <td>50.033333</td>\n",
       "      <td>131.194427</td>\n",
       "      <td>4475.603842</td>\n",
       "      <td>3961.053100</td>\n",
       "      <td>3302.766768</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.570714</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16068</th>\n",
       "      <td>wb2b3</td>\n",
       "      <td>wb2b3</td>\n",
       "      <td>26</td>\n",
       "      <td>132.267949</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>184.054177</td>\n",
       "      <td>2847.508584</td>\n",
       "      <td>1115.643962</td>\n",
       "      <td>5363.755756</td>\n",
       "      <td>4.807692</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.154423</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16094</th>\n",
       "      <td>wb2b9</td>\n",
       "      <td>wb2b9</td>\n",
       "      <td>11</td>\n",
       "      <td>62.518182</td>\n",
       "      <td>64.883333</td>\n",
       "      <td>51.428689</td>\n",
       "      <td>1559.609883</td>\n",
       "      <td>378.245321</td>\n",
       "      <td>3335.194155</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.119177</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>wb2bd</td>\n",
       "      <td>wb2bd</td>\n",
       "      <td>14</td>\n",
       "      <td>56.386905</td>\n",
       "      <td>24.066667</td>\n",
       "      <td>73.205417</td>\n",
       "      <td>6450.858098</td>\n",
       "      <td>1978.203449</td>\n",
       "      <td>8006.088833</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.312175</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16143</th>\n",
       "      <td>wb4s6</td>\n",
       "      <td>wb4s6</td>\n",
       "      <td>14</td>\n",
       "      <td>48.585714</td>\n",
       "      <td>34.675000</td>\n",
       "      <td>41.307894</td>\n",
       "      <td>2357.588932</td>\n",
       "      <td>1340.170992</td>\n",
       "      <td>2140.338490</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.585887</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_geohash5 end_geohash5  trip_count  m_duration_min  \\\n",
       "25             qpz6e        qpz6e          42       87.852381   \n",
       "29             qpz6e        qpz6s          10       43.406667   \n",
       "35             qpz6g        qpz6e          10       57.320000   \n",
       "36             qpz6g        qpz6g          21       88.769048   \n",
       "58             qpz6s        qpz6s          38       80.742982   \n",
       "...              ...          ...         ...             ...   \n",
       "16059          wb2b2        wb2b3          12      103.481944   \n",
       "16068          wb2b3        wb2b3          26      132.267949   \n",
       "16094          wb2b9        wb2b9          11       62.518182   \n",
       "16102          wb2bd        wb2bd          14       56.386905   \n",
       "16143          wb4s6        wb4s6          14       48.585714   \n",
       "\n",
       "       mdn_duration_min  sd_duration_min   m_length_m  mdn_length_m  \\\n",
       "25            32.208333       168.030579  4676.194708   1523.026116   \n",
       "29            24.833333        36.721081  3931.408664   3428.999614   \n",
       "35            28.300000        58.491738  7226.994729   5089.530602   \n",
       "36            42.916667       111.668216  4799.423202   1268.281055   \n",
       "58            32.708333        96.794736  2479.739199   1489.384521   \n",
       "...                 ...              ...          ...           ...   \n",
       "16059         50.033333       131.194427  4475.603842   3961.053100   \n",
       "16068         38.800000       184.054177  2847.508584   1115.643962   \n",
       "16094         64.883333        51.428689  1559.609883    378.245321   \n",
       "16102         24.066667        73.205417  6450.858098   1978.203449   \n",
       "16143         34.675000        41.307894  2357.588932   1340.170992   \n",
       "\n",
       "        sd_length_m  m_points_no  mdn_points_no  sd_points_no  local_date  \n",
       "25     13531.575806    10.119048            5.0     15.381653    20190106  \n",
       "29      2486.709348     4.900000            4.5      1.852926    20190106  \n",
       "35      5321.204434     7.200000            8.0      3.190263    20190106  \n",
       "36      7019.272456    15.904762            5.0     37.158989    20190106  \n",
       "58      3569.710189     4.500000            4.0      2.214815    20190106  \n",
       "...             ...          ...            ...           ...         ...  \n",
       "16059   3302.766768     5.750000            5.5      3.570714    20190106  \n",
       "16068   5363.755756     4.807692            5.0      2.154423    20190106  \n",
       "16094   3335.194155     4.090909            4.0      2.119177    20190106  \n",
       "16102   8006.088833     4.500000            4.5      2.312175    20190106  \n",
       "16143   2140.338490     4.071429            3.5      2.585887    20190106  \n",
       "\n",
       "[1021 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query single\n",
    "country_code = 'ID'\n",
    "event_date = 20190106\n",
    "\n",
    "pe_tj_df = sql_engine.read_sql(\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "        cuebiq_id,\n",
    "        start_lat,\n",
    "        start_lng,\n",
    "        end_lat,\n",
    "        end_lng,\n",
    "        duration_minutes,\n",
    "        length_meters,\n",
    "        number_of_points\n",
    "    FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "    WHERE \n",
    "        event_date = {event_date}\n",
    "        AND end_country = '{country_code}' \n",
    "        AND start_country = '{country_code}' \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# pe_tj_df\n",
    "\n",
    "# Encode geohashes\n",
    "pe_tj_df['start_geohash5'] = pe_tj_df.apply(\n",
    "    lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=5), axis=1)\n",
    "pe_tj_df['end_geohash5'] = pe_tj_df.apply(\n",
    "    lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=5), axis=1)\n",
    "\n",
    "# Add user numbers to the aggregated data\n",
    "aggregated_df5 = pe_tj_df.groupby(['start_geohash5', 'end_geohash5']).agg({\n",
    "    'cuebiq_id': 'count',\n",
    "    'duration_minutes': ['mean', 'median', 'std'],\n",
    "    'length_meters': ['mean', 'median', 'std'],\n",
    "    'number_of_points': ['mean', 'median', 'std']\n",
    "}).reset_index()\n",
    "aggregated_df5.columns = ['start_geohash5', 'end_geohash5', 'trip_count', \n",
    "                          'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                          'm_length_m', 'mdn_length_m', 'sd_length_m',\n",
    "                          'm_points_no', 'mdn_points_no', 'sd_points_no']\n",
    "\n",
    "# Filter aggregated data\n",
    "filtered_df5 = aggregated_df5.loc[aggregated_df5['trip_count'] > 9]\n",
    "filtered_df5['local_date'] = event_date\n",
    "filtered_df5 = filtered_df5.astype({'trip_count': 'int'})\n",
    "filtered_df5\n",
    "\n",
    "agg_file_name = f\"od_{country_code.lower()}_{event_date}_agg5_10\"\n",
    "filtered_df5.to_csv('/home/jovyan/Data/TJ/' + country_code + '/' + agg_file_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788043f7-bd0b-4189-af49-ab6f7b5c1f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad6207-9c36-403e-a2c9-473609211506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6ab54-7ea9-4f44-8d58-48a9c5ed510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9950b-f813-4496-95ee-8a850ab07181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2f14e-fa1b-4810-a38d-e529d81569d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf17b0-d474-4e16-80a7-0538ca8d1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa5e4671-e3f7-4af4-92ec-49e7a9c8235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to process data for a single day\n",
    "def process_day(event_date, country_code, sql_engine):\n",
    "    try:\n",
    "        # Read data from the SQL table\n",
    "        pe_tj_df = sql_engine.read_sql(\n",
    "            f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                cuebiq_id,\n",
    "                start_lat,\n",
    "                start_lng,\n",
    "                end_lat,\n",
    "                end_lng,\n",
    "                duration_minutes,\n",
    "                length_meters,\n",
    "                number_of_points\n",
    "            FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "            WHERE \n",
    "                event_date = {event_date}\n",
    "                AND end_country = '{country_code}' \n",
    "                AND start_country = '{country_code}' \n",
    "            \"\"\"\n",
    "        )\n",
    "        logging.info(f\"Executing SQL query for date {event_date}\")\n",
    "        \n",
    "        # Encode geohashes\n",
    "        try:\n",
    "            pe_tj_df['start_geohash5'] = pe_tj_df.apply(\n",
    "                lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=5) if pd.notnull(x['start_lat']) and pd.notnull(x['start_lng']) else None, axis=1)\n",
    "            pe_tj_df['end_geohash5'] = pe_tj_df.apply(\n",
    "                lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=5) if pd.notnull(x['end_lat']) and pd.notnull(x['end_lng']) else None, axis=1)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error encoding geohashes for date {event_date}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Add user numbers to the aggregated data\n",
    "        try:\n",
    "            if not pe_tj_df.empty:\n",
    "                aggregated_df5 = pe_tj_df.groupby(['start_geohash5', 'end_geohash5']).agg({\n",
    "                    'cuebiq_id': 'count',\n",
    "                    'duration_minutes': ['mean', 'median', 'std'],\n",
    "                    'length_meters': ['mean', 'median', 'std'],\n",
    "                    'number_of_points': ['mean', 'median', 'std']\n",
    "                }).reset_index()\n",
    "                aggregated_df5.columns = ['start_geohash5', 'end_geohash5', 'trip_count', \n",
    "                                          'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                                          'm_length_m', 'mdn_length_m', 'sd_length_m',\n",
    "                                          'm_points_no', 'mdn_points_no', 'sd_points_no']\n",
    "            else:\n",
    "                logging.info(f\"No data to aggregate for date {event_date}\")\n",
    "                return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error aggregating data for date {event_date}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Filter aggregated data\n",
    "        try:\n",
    "            filtered_df5 = aggregated_df5.loc[aggregated_df5['trip_count'] > 9].copy()\n",
    "            filtered_df5['local_date'] = event_date\n",
    "            filtered_df5 = filtered_df5.astype({'trip_count': 'int'})\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error filtering or assigning data for date {event_date}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        return filtered_df5\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing data for date {event_date}: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9771058-c43d-4cf3-97eb-3f91d2ca61ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 19:33:22,425 - INFO - Executing SQL query for date 20190106\n",
      "2024-06-25 19:33:33,833 - INFO - Executing SQL query for date 20190210\n",
      "2024-06-25 19:33:48,799 - INFO - Executing SQL query for date 20190214\n",
      "2024-06-25 19:34:06,726 - INFO - Executing SQL query for date 20190304\n",
      "2024-06-25 19:34:26,340 - INFO - Executing SQL query for date 20190306\n",
      "2024-06-25 19:34:44,650 - INFO - Executing SQL query for date 20190316\n",
      "2024-06-25 19:35:03,558 - INFO - Executing SQL query for date 20190320\n",
      "2024-06-25 19:35:22,995 - INFO - Executing SQL query for date 20190327\n",
      "2024-06-25 19:35:42,503 - INFO - Executing SQL query for date 20190724\n",
      "2024-06-25 19:35:59,197 - INFO - Executing SQL query for date 20190804\n",
      "2024-06-25 19:36:17,703 - INFO - Executing SQL query for date 20190808\n",
      "2024-06-25 19:36:36,429 - INFO - Executing SQL query for date 20190810\n",
      "2024-06-25 19:36:54,882 - INFO - Executing SQL query for date 20190812\n",
      "2024-06-25 19:37:16,645 - INFO - Executing SQL query for date 20190913\n",
      "2024-06-25 19:37:39,797 - INFO - Executing SQL query for date 20190925\n",
      "2024-06-25 19:38:02,229 - INFO - Executing SQL query for date 20191023\n",
      "2024-06-25 19:38:26,716 - INFO - Executing SQL query for date 20191104\n",
      "2024-06-25 19:38:42,930 - INFO - Executing SQL query for date 20191126\n",
      "2024-06-25 19:38:54,605 - INFO - Executing SQL query for date 20191203\n",
      "2024-06-25 19:39:05,743 - INFO - Executing SQL query for date 20191204\n",
      "2024-06-25 19:39:17,951 - INFO - Executing SQL query for date 20191205\n",
      "2024-06-25 19:39:30,651 - INFO - Executing SQL query for date 20191210\n",
      "2024-06-25 19:39:42,489 - INFO - Executing SQL query for date 20191218\n"
     ]
    }
   ],
   "source": [
    "# List of specific dates to process\n",
    "date_list = [\n",
    "    '20190106', '20190210', '20190214', '20190304', '20190306', \n",
    "    '20190316', '20190320', '20190327', '20190724', '20190804', \n",
    "    '20190808', '20190810', '20190812', '20190913', '20190925', \n",
    "    '20191023', '20191104', '20191126', '20191203', '20191204', \n",
    "    '20191205', '20191210', '20191218'\n",
    "]\n",
    "\n",
    "country_code = 'ID'\n",
    "all_days_df = pd.DataFrame()\n",
    "\n",
    "# Process each day and concatenate the results\n",
    "for event_date in date_list:\n",
    "    filtered_df5 = process_day(event_date, country_code, sql_engine)\n",
    "    if not filtered_df5.empty:\n",
    "        all_days_df = pd.concat([all_days_df, filtered_df5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e4db05-2639-4d55-adae-fec758f9c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_geohash5</th>\n",
       "      <th>end_geohash5</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>m_duration_min</th>\n",
       "      <th>mdn_duration_min</th>\n",
       "      <th>sd_duration_min</th>\n",
       "      <th>m_length_m</th>\n",
       "      <th>mdn_length_m</th>\n",
       "      <th>sd_length_m</th>\n",
       "      <th>m_points_no</th>\n",
       "      <th>mdn_points_no</th>\n",
       "      <th>sd_points_no</th>\n",
       "      <th>local_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qpz6e</td>\n",
       "      <td>qpz6e</td>\n",
       "      <td>42</td>\n",
       "      <td>87.852381</td>\n",
       "      <td>32.208333</td>\n",
       "      <td>168.030579</td>\n",
       "      <td>4676.194708</td>\n",
       "      <td>1523.026116</td>\n",
       "      <td>13531.575806</td>\n",
       "      <td>10.119048</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.381653</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qpz6e</td>\n",
       "      <td>qpz6s</td>\n",
       "      <td>10</td>\n",
       "      <td>43.406667</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>36.721081</td>\n",
       "      <td>3931.408664</td>\n",
       "      <td>3428.999614</td>\n",
       "      <td>2486.709348</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.852926</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qpz6g</td>\n",
       "      <td>qpz6e</td>\n",
       "      <td>10</td>\n",
       "      <td>57.320000</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>58.491738</td>\n",
       "      <td>7226.994729</td>\n",
       "      <td>5089.530602</td>\n",
       "      <td>5321.204434</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.190263</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>qpz6g</td>\n",
       "      <td>qpz6g</td>\n",
       "      <td>21</td>\n",
       "      <td>88.769048</td>\n",
       "      <td>42.916667</td>\n",
       "      <td>111.668216</td>\n",
       "      <td>4799.423202</td>\n",
       "      <td>1268.281055</td>\n",
       "      <td>7019.272456</td>\n",
       "      <td>15.904762</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.158989</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>qpz6s</td>\n",
       "      <td>qpz6s</td>\n",
       "      <td>38</td>\n",
       "      <td>80.742982</td>\n",
       "      <td>32.708333</td>\n",
       "      <td>96.794736</td>\n",
       "      <td>2479.739199</td>\n",
       "      <td>1489.384521</td>\n",
       "      <td>3569.710189</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.214815</td>\n",
       "      <td>20190106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>wb2b7</td>\n",
       "      <td>wb2b7</td>\n",
       "      <td>11</td>\n",
       "      <td>24.584848</td>\n",
       "      <td>16.450000</td>\n",
       "      <td>25.057702</td>\n",
       "      <td>826.650948</td>\n",
       "      <td>362.350495</td>\n",
       "      <td>770.842073</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.433369</td>\n",
       "      <td>20191218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15215</th>\n",
       "      <td>wb2b8</td>\n",
       "      <td>wb2b8</td>\n",
       "      <td>12</td>\n",
       "      <td>23.944444</td>\n",
       "      <td>13.816667</td>\n",
       "      <td>23.122735</td>\n",
       "      <td>5091.193739</td>\n",
       "      <td>251.602016</td>\n",
       "      <td>13634.021100</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.378954</td>\n",
       "      <td>20191218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15229</th>\n",
       "      <td>wb2bd</td>\n",
       "      <td>wb2bd</td>\n",
       "      <td>15</td>\n",
       "      <td>49.720000</td>\n",
       "      <td>28.083333</td>\n",
       "      <td>62.051096</td>\n",
       "      <td>2538.492526</td>\n",
       "      <td>966.270617</td>\n",
       "      <td>4906.471853</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.352247</td>\n",
       "      <td>20191218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>wb4s6</td>\n",
       "      <td>wb4s6</td>\n",
       "      <td>24</td>\n",
       "      <td>42.283333</td>\n",
       "      <td>14.275000</td>\n",
       "      <td>62.885850</td>\n",
       "      <td>2453.871182</td>\n",
       "      <td>760.669901</td>\n",
       "      <td>5072.246530</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.729336</td>\n",
       "      <td>20191218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>wb4sd</td>\n",
       "      <td>wb4sd</td>\n",
       "      <td>10</td>\n",
       "      <td>131.903333</td>\n",
       "      <td>77.766667</td>\n",
       "      <td>205.034393</td>\n",
       "      <td>1467.626970</td>\n",
       "      <td>1130.739650</td>\n",
       "      <td>1444.669206</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.590581</td>\n",
       "      <td>20191218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48541 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_geohash5 end_geohash5  trip_count  m_duration_min  \\\n",
       "25             qpz6e        qpz6e          42       87.852381   \n",
       "29             qpz6e        qpz6s          10       43.406667   \n",
       "35             qpz6g        qpz6e          10       57.320000   \n",
       "36             qpz6g        qpz6g          21       88.769048   \n",
       "58             qpz6s        qpz6s          38       80.742982   \n",
       "...              ...          ...         ...             ...   \n",
       "15210          wb2b7        wb2b7          11       24.584848   \n",
       "15215          wb2b8        wb2b8          12       23.944444   \n",
       "15229          wb2bd        wb2bd          15       49.720000   \n",
       "15272          wb4s6        wb4s6          24       42.283333   \n",
       "15278          wb4sd        wb4sd          10      131.903333   \n",
       "\n",
       "       mdn_duration_min  sd_duration_min   m_length_m  mdn_length_m  \\\n",
       "25            32.208333       168.030579  4676.194708   1523.026116   \n",
       "29            24.833333        36.721081  3931.408664   3428.999614   \n",
       "35            28.300000        58.491738  7226.994729   5089.530602   \n",
       "36            42.916667       111.668216  4799.423202   1268.281055   \n",
       "58            32.708333        96.794736  2479.739199   1489.384521   \n",
       "...                 ...              ...          ...           ...   \n",
       "15210         16.450000        25.057702   826.650948    362.350495   \n",
       "15215         13.816667        23.122735  5091.193739    251.602016   \n",
       "15229         28.083333        62.051096  2538.492526    966.270617   \n",
       "15272         14.275000        62.885850  2453.871182    760.669901   \n",
       "15278         77.766667       205.034393  1467.626970   1130.739650   \n",
       "\n",
       "        sd_length_m  m_points_no  mdn_points_no  sd_points_no local_date  \n",
       "25     13531.575806    10.119048            5.0     15.381653   20190106  \n",
       "29      2486.709348     4.900000            4.5      1.852926   20190106  \n",
       "35      5321.204434     7.200000            8.0      3.190263   20190106  \n",
       "36      7019.272456    15.904762            5.0     37.158989   20190106  \n",
       "58      3569.710189     4.500000            4.0      2.214815   20190106  \n",
       "...             ...          ...            ...           ...        ...  \n",
       "15210    770.842073     3.363636            3.0      1.433369   20191218  \n",
       "15215  13634.021100     3.416667            3.0      1.378954   20191218  \n",
       "15229   4906.471853     3.600000            3.0      1.352247   20191218  \n",
       "15272   5072.246530     4.166667            3.5      2.729336   20191218  \n",
       "15278   1444.669206     4.400000            3.0      2.590581   20191218  \n",
       "\n",
       "[48541 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a150d96e-8311-4268-9172-a6fa7f5ba1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_df.to_csv('/home/jovyan/Data/TJ/' + 'ID_MissingDates.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe55a9-be17-4357-862e-c09c797397e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df0a19-7477-4067-adef-72aa1d701faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb6f36-52ec-4aca-86d5-1fec273ea6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5ae12-830c-496c-be73-f527048603c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff191f4-b11e-4639-9c4e-502decf49696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d565d9-6119-467c-bef4-082acc505204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca5d0d-a0f6-43b0-af28-3d06ec9a23b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a779f-0b84-40f8-a379-acf4490e1a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
