{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb444a1e-bb21-4758-8fe0-4b12335da83f",
   "metadata": {},
   "source": [
    "This is daily aggregation for pd3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d289ed9b-b5c6-42f8-9b8a-8d2653a94f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%config SqlMagic.autolimit=0\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaylimit=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7304cfd6-5f4e-4fd1-9fcb-e4f799127977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @cuebiq/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql trino://localhost:9090/cuebiq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ccb1e3-ccad-4833-b2fd-3646480078ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geohash2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geohash2) (0.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geohash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d54996b-6d6c-475c-ad0a-0d895f41ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import geohash2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe46e82-6e2f-463e-b61d-c09c017bf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2185a185-453b-4e44-88ed-cccba705c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data with retry mechanism\n",
    "def insert_data_with_retry(df, table_name, con, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                con, \n",
    "                index=False, \n",
    "                if_exists=\"append\", \n",
    "                method=\"multi\"\n",
    "            )\n",
    "            logging.info(f\"Inserted data into table {table_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(f\"Failed to insert data into table {table_name} after {retries} attempts\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1706be65-38bc-40c2-a13c-07032a38ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'IN'\n",
    "start_date = 20191115\n",
    "end_date = 20191115\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\"\n",
    "\n",
    "# Convert integer dates to datetime objects\n",
    "start_date_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "end_date_dt = datetime.strptime(str(end_date), '%Y%m%d')\n",
    "\n",
    "# Define the sorted longitude boundaries\n",
    "sorted_lons = [67.5, 68.90625, 70.3125, 71.71875, 73.125, \n",
    "               74.53125, 75.9375, 77.34375, 78.75, 80.15625, \n",
    "               81.5625, 82.96875, 84.375, 85.78125, 87.1875, \n",
    "               88.59375]\n",
    "\n",
    "# Initialize a list to store failed insertions\n",
    "failed_inserts = []\n",
    "# Define the buffer value\n",
    "buffer_value = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "148ea67f-8013-4887-867f-4f30f018dc5a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:57:27,171 - INFO - Executing SQL query for date 20191115 and longitude range 47.5 to 67.5\n",
      "2024-07-02 16:57:38,700 - ERROR - Error while processing data for date 20191115 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 16:57:38,701 - INFO - Executing SQL query for date 20191115 and longitude range 67.5 to 68.90625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting SQL query for date \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_current_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and longitude range \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_lon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_lon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     pe_dl_table_gen \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Convert the generator to a DataFrame\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pe_dl_table_gen]\n",
      "Cell \u001b[0;32mIn [13], line 26\u001b[0m, in \u001b[0;36mTrinoEngine.read_sql_chunked\u001b[0;34m(self, query, chunksize)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_sql_chunked\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pandas/io/sql.py:590\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    582\u001b[0m         sql,\n\u001b[1;32m    583\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pandas/io/sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 1560\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pandas/io/sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:402\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_warning:\n\u001b[1;32m    401\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:3257\u001b[0m, in \u001b[0;36mEngine.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;124;03m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;124;03m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[1;32m   3241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3254\u001b[0m \n\u001b[1;32m   3255\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(close_with_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 3257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1365\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(statement, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m   1357\u001b[0m     util\u001b[38;5;241m.\u001b[39mwarn_deprecated_20(\n\u001b[1;32m   1358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a string to Connection.execute() is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver-level SQL string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1669\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         (\n\u001b[1;32m   1660\u001b[0m             statement,\n\u001b[1;32m   1661\u001b[0m             distilled_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1665\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[1;32m   1666\u001b[0m         )\n\u001b[1;32m   1668\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[0;32m-> 1669\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1943\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1940\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1943\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2128\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2124\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   2125\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m   2126\u001b[0m         )\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2128\u001b[0m         \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2131\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/util/compat.py:211\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    208\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1900\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1906\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1907\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1912\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py:365\u001b[0m, in \u001b[0;36mTrinoDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m, cursor: Cursor, statement: \u001b[38;5;28mstr\u001b[39m, parameters: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], context: DefaultExecutionContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    364\u001b[0m ):\n\u001b[0;32m--> 365\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py:501\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, params)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query \u001b[38;5;241m=\u001b[39m trino\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mTrinoQuery(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, query\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m    500\u001b[0m                                           legacy_primitive_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy_primitive_types)\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py:821\u001b[0m, in \u001b[0;36mTrinoQuery.execute\u001b[0;34m(self, additional_http_headers)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# Execute should block until at least one row is received or query is finished or cancelled\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinished \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py:837\u001b[0m, in \u001b[0;36mTrinoQuery.fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[Any]]:\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;124;03m\"\"\"Continue fetching data for the current query_id\"\"\"\u001b[39;00m\n\u001b[0;32m--> 837\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mprocess(response)\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state(status)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py:579\u001b[0m, in \u001b[0;36mTrinoRequest.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROXIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py:886\u001b[0m, in \u001b[0;36m_retry_with.<locals>.wrapper.<locals>.decorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_attempts \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 886\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(guard(result) \u001b[38;5;28;01mfor\u001b[39;00m guard \u001b[38;5;129;01min\u001b[39;00m conditions):\n\u001b[1;32m    888\u001b[0m             handle_retry\u001b[38;5;241m.\u001b[39mretry(func, args, kwargs, \u001b[38;5;28;01mNone\u001b[39;00m, attempt)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    599\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through each day from start_date to end_date\n",
    "current_date = start_date_dt\n",
    "while current_date <= end_date_dt:\n",
    "    try:\n",
    "        # Calculate the lookback and lookahead dates\n",
    "        lookback_date = current_date - timedelta(days=1)\n",
    "        lookahead_date = current_date + timedelta(days=35)\n",
    "        \n",
    "        # Format dates for the SQL query\n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_current_date = current_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Loop through each longitude range\n",
    "        for i in range(len(sorted_lons) + 1):\n",
    "            if i == 0:\n",
    "                min_lon = sorted_lons[i] - buffer_value\n",
    "                max_lon = sorted_lons[i]\n",
    "            elif i == len(sorted_lons):\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i - 1] + buffer_value\n",
    "            else:\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i]\n",
    "            \n",
    "            # Construct the SQL query\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id, \n",
    "                event_zoned_datetime, \n",
    "                processing_date,\n",
    "                lat,\n",
    "                lng\n",
    "            FROM {pe_dl_table}\n",
    "            WHERE \n",
    "                processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "                AND country_code = '{country_code}' \n",
    "                AND event_zoned_datetime IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "                AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "                AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "            \n",
    "            try:\n",
    "                pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "                \n",
    "                # Convert the generator to a DataFrame\n",
    "                chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "                if chunks:\n",
    "                    pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                    \n",
    "                    # Calculate geohashes\n",
    "                    pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                    \n",
    "                    # Aggregate data for geohash3\n",
    "                    aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                        no_of_points=('geohash3', 'size'),\n",
    "                        no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Filter rows with no_of_unique_users > 10\n",
    "                    filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                    \n",
    "                    # Add the local_date column\n",
    "                    filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                    \n",
    "                    # Insert filtered aggregated data for geohash3 into SQL table\n",
    "                    if not filtered_data_3.empty:\n",
    "                        table_name_agg3 = f\"pd_{country_code.lower()}_{formatted_current_date}_agg3_2\"\n",
    "                        if not insert_data_with_retry(filtered_data_3, table_name_agg3, con):\n",
    "                            failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "                failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n",
    "    \n",
    "    # Move to the next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9acd1-22f1-4d35-adb5-e3c7cc97b38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38845288-a751-406b-aa05-2f614fc729b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c793941-1c1c-428f-96d3-1780253886ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9467a-19fa-484b-b17a-a69b4754c265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ddd88-ecd7-4e2d-8644-c23c7a4a8e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ed585-830c-4d5b-9e12-f981b1e987cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8d5db-61f3-4a52-bb71-95108bf4d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2e7e0d-733e-44a1-b396-40e14e75c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize the SQL engine\n",
    "sql_engine = TrinoEngine()\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "# Define the buffer value\n",
    "buffer_value = 20\n",
    "failed_inserts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1599829-fd47-4e09-bee4-2bb7bb18f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data for a given date and longitude range\n",
    "def process_data_for_date_and_lon(formatted_current_date, min_lon, max_lon):\n",
    "    try:\n",
    "        lookback_date = datetime.strptime(formatted_current_date, '%Y%m%d') - timedelta(days=1)\n",
    "        lookahead_date = datetime.strptime(formatted_current_date, '%Y%m%d') + timedelta(days=35)\n",
    "        \n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            cuebiq_id, \n",
    "            event_zoned_datetime, \n",
    "            processing_date,\n",
    "            lat,\n",
    "            lng\n",
    "        FROM cuebiq.paas_cda_pe_v3.device_location_uplevelled\n",
    "        WHERE \n",
    "            processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "            AND country_code = '{country_code}' \n",
    "            AND event_zoned_datetime IS NOT NULL\n",
    "            AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "            AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "            AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "        \n",
    "        try:\n",
    "            pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "            \n",
    "            chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "            if chunks:\n",
    "                pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                \n",
    "                pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                \n",
    "                aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                    no_of_points=('geohash3', 'size'),\n",
    "                    no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                ).reset_index()\n",
    "                \n",
    "                filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                \n",
    "                filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                \n",
    "                if not filtered_data_3.empty:\n",
    "                    table_name_agg3 = f\"pd_{country_code.lower()}_{formatted_current_date}_agg3\"\n",
    "                    if not insert_data_with_retry(filtered_data_3, table_name_agg3, con):\n",
    "                        failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "            failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2163024-4cec-490b-9e23-c946df44c39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e239e-b566-4eaf-aba7-65eb0552cbfd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:47:20,183 - INFO - Executing SQL query for date 20190603 and longitude range 73.125 to 74.53125\n",
      "2024-06-13 22:48:28,948 - INFO - Inserted data into table pd_in_20190603_agg3\n",
      "2024-06-13 22:48:29,020 - INFO - Executing SQL query for date 20190620 and longitude range 87.1875 to 88.59375\n",
      "2024-06-13 22:49:25,742 - INFO - Inserted data into table pd_in_20190620_agg3\n",
      "2024-06-13 22:49:25,797 - INFO - Executing SQL query for date 20190620 and longitude range 88.59375 to 108.59375\n",
      "2024-06-13 22:50:08,892 - INFO - Inserted data into table pd_in_20190620_agg3\n",
      "2024-06-13 22:50:08,928 - INFO - Executing SQL query for date 20190715 and longitude range 71.71875 to 73.125\n",
      "2024-06-13 22:51:37,198 - INFO - Inserted data into table pd_in_20190715_agg3\n",
      "2024-06-13 22:51:37,304 - INFO - Executing SQL query for date 20190721 and longitude range 88.59375 to 108.59375\n",
      "2024-06-13 22:52:19,114 - INFO - Inserted data into table pd_in_20190721_agg3\n",
      "2024-06-13 22:52:19,145 - INFO - Executing SQL query for date 20190723 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 22:54:36,292 - INFO - Inserted data into table pd_in_20190723_agg3\n",
      "2024-06-13 22:54:36,471 - INFO - Executing SQL query for date 20190723 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 22:56:35,221 - INFO - Inserted data into table pd_in_20190723_agg3\n",
      "2024-06-13 22:56:35,370 - INFO - Executing SQL query for date 20190724 and longitude range 80.15625 to 81.5625\n",
      "2024-06-13 22:57:28,857 - INFO - Inserted data into table pd_in_20190724_agg3\n",
      "2024-06-13 22:57:28,906 - INFO - Executing SQL query for date 20190724 and longitude range 81.5625 to 82.96875\n",
      "2024-06-13 22:58:06,361 - INFO - Inserted data into table pd_in_20190724_agg3\n",
      "2024-06-13 22:58:06,384 - INFO - Executing SQL query for date 20190731 and longitude range 67.5 to 68.90625\n",
      "2024-06-13 22:58:27,489 - INFO - Inserted data into table pd_in_20190731_agg3\n",
      "2024-06-13 22:58:27,490 - INFO - Executing SQL query for date 20190801 and longitude range 73.125 to 74.53125\n",
      "2024-06-13 22:59:33,715 - INFO - Inserted data into table pd_in_20190801_agg3\n",
      "2024-06-13 22:59:33,782 - INFO - Executing SQL query for date 20190801 and longitude range 74.53125 to 75.9375\n",
      "2024-06-13 23:01:03,275 - INFO - Inserted data into table pd_in_20190801_agg3\n",
      "2024-06-13 23:01:03,377 - INFO - Executing SQL query for date 20190804 and longitude range 82.96875 to 84.375\n",
      "2024-06-13 23:01:43,310 - INFO - Inserted data into table pd_in_20190804_agg3\n",
      "2024-06-13 23:01:43,333 - INFO - Executing SQL query for date 20190804 and longitude range 84.375 to 85.78125\n",
      "2024-06-13 23:02:21,824 - INFO - Inserted data into table pd_in_20190804_agg3\n",
      "2024-06-13 23:02:21,854 - INFO - Executing SQL query for date 20190808 and longitude range 78.75 to 80.15625\n",
      "2024-06-13 23:03:22,087 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:03:22,145 - INFO - Executing SQL query for date 20190808 and longitude range 80.15625 to 81.5625\n",
      "2024-06-13 23:04:17,367 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:04:17,417 - INFO - Executing SQL query for date 20190808 and longitude range 81.5625 to 82.96875\n",
      "2024-06-13 23:04:54,242 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:04:54,265 - INFO - Executing SQL query for date 20190812 and longitude range 71.71875 to 73.125\n",
      "2024-06-13 23:06:29,107 - INFO - Inserted data into table pd_in_20190812_agg3\n",
      "2024-06-13 23:06:29,213 - INFO - Executing SQL query for date 20190815 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 23:08:31,910 - INFO - Inserted data into table pd_in_20190815_agg3\n",
      "2024-06-13 23:08:32,063 - INFO - Executing SQL query for date 20190815 and longitude range 78.75 to 80.15625\n",
      "2024-06-13 23:09:34,368 - INFO - Inserted data into table pd_in_20190815_agg3\n",
      "2024-06-13 23:09:34,430 - INFO - Executing SQL query for date 20190820 and longitude range 67.5 to 68.90625\n",
      "2024-06-13 23:09:54,904 - INFO - Inserted data into table pd_in_20190820_agg3\n",
      "2024-06-13 23:09:54,905 - INFO - Executing SQL query for date 20190821 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 23:12:13,985 - INFO - Inserted data into table pd_in_20190821_agg3\n",
      "2024-06-13 23:12:14,164 - INFO - Executing SQL query for date 20190824 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 23:14:31,670 - INFO - Inserted data into table pd_in_20190824_agg3\n",
      "2024-06-13 23:14:31,850 - INFO - Executing SQL query for date 20190824 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 23:16:31,769 - INFO - Inserted data into table pd_in_20190824_agg3\n",
      "2024-06-13 23:16:31,926 - INFO - Data extraction, aggregation, and saving completed for missing sections.\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters\n",
    "country_code = 'IN'\n",
    "missing_sections = [\n",
    "    ('20190603', 73.125, 74.53125),\n",
    "    ('20190620', 87.1875, 88.59375),\n",
    "    ('20190620', 88.59375, 108.59375),\n",
    "    ('20190715', 71.71875, 73.125),\n",
    "    ('20190721', 88.59375, 108.59375),\n",
    "    ('20190723', 75.9375, 77.34375),\n",
    "    ('20190723', 77.34375, 78.75),\n",
    "    ('20190724', 80.15625, 81.5625),\n",
    "    ('20190724', 81.5625, 82.96875),\n",
    "    ('20190731', 67.5, 68.90625),\n",
    "    ('20190801', 73.125, 74.53125),\n",
    "    ('20190801', 74.53125, 75.9375),\n",
    "    ('20190804', 82.96875, 84.375),\n",
    "    ('20190804', 84.375, 85.78125),\n",
    "    ('20190808', 78.75, 80.15625),\n",
    "    ('20190808', 80.15625, 81.5625),\n",
    "    ('20190808', 81.5625, 82.96875),\n",
    "    ('20190812', 71.71875, 73.125),\n",
    "    ('20190815', 77.34375, 78.75),\n",
    "    ('20190815', 78.75, 80.15625),\n",
    "    ('20190820', 67.5, 68.90625),\n",
    "    ('20190821', 75.9375, 77.34375),\n",
    "    ('20190824', 75.9375, 77.34375),\n",
    "    ('20190824', 77.34375, 78.75)\n",
    "]\n",
    "\n",
    "# Loop through each missing section\n",
    "for section in missing_sections:\n",
    "    formatted_current_date, min_lon, max_lon = section\n",
    "    process_data_for_date_and_lon(formatted_current_date, min_lon, max_lon)\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed for missing sections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f30c0-9165-4612-ba42-d9cb0b4f74c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0b3d11-caf2-4239-b90d-f539b5a45fdb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 04:22:29,932 - INFO - Executing SQL query for date 20191126 and longitude range 47.5 to 67.5\n",
      "2024-07-03 04:22:36,282 - ERROR - Error while processing data for date 20191126 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-03 04:22:36,283 - INFO - Executing SQL query for date 20191126 and longitude range 67.5 to 68.90625\n",
      "2024-07-03 04:22:50,493 - INFO - Executing SQL query for date 20191126 and longitude range 68.90625 to 70.3125\n",
      "2024-07-03 04:23:29,484 - INFO - Executing SQL query for date 20191126 and longitude range 70.3125 to 71.71875\n",
      "2024-07-03 04:23:47,342 - INFO - Executing SQL query for date 20191126 and longitude range 71.71875 to 73.125\n",
      "2024-07-03 04:24:36,201 - INFO - Executing SQL query for date 20191126 and longitude range 73.125 to 74.53125\n",
      "2024-07-03 04:25:16,751 - INFO - Executing SQL query for date 20191126 and longitude range 74.53125 to 75.9375\n",
      "2024-07-03 04:26:26,637 - INFO - Executing SQL query for date 20191126 and longitude range 75.9375 to 77.34375\n",
      "2024-07-03 04:27:43,008 - INFO - Executing SQL query for date 20191126 and longitude range 77.34375 to 78.75\n",
      "2024-07-03 04:28:45,959 - INFO - Executing SQL query for date 20191126 and longitude range 78.75 to 80.15625\n",
      "2024-07-03 04:29:26,665 - INFO - Executing SQL query for date 20191126 and longitude range 80.15625 to 81.5625\n",
      "2024-07-03 04:30:20,334 - INFO - Executing SQL query for date 20191126 and longitude range 81.5625 to 82.96875\n",
      "2024-07-03 04:30:48,408 - INFO - Executing SQL query for date 20191126 and longitude range 82.96875 to 84.375\n",
      "2024-07-03 04:31:20,517 - INFO - Executing SQL query for date 20191126 and longitude range 84.375 to 85.78125\n",
      "2024-07-03 04:31:43,114 - INFO - Executing SQL query for date 20191126 and longitude range 85.78125 to 87.1875\n",
      "2024-07-03 04:32:32,298 - INFO - Executing SQL query for date 20191126 and longitude range 87.1875 to 88.59375\n",
      "2024-07-03 04:33:04,076 - INFO - Executing SQL query for date 20191126 and longitude range 88.59375 to 108.59375\n",
      "2024-07-03 04:33:42,875 - INFO - Data extraction, aggregation, and saving completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed inserts:\n",
      "('20191126', 47.5, 67.5)\n"
     ]
    }
   ],
   "source": [
    "# Define the specific dates to run the script\n",
    "# specific_dates = ['20190522', '20191226']\n",
    "specific_dates = ['20191126']\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize a list to store failed inserts\n",
    "failed_inserts = []\n",
    "\n",
    "# Loop through each specific date\n",
    "for date_str in specific_dates:\n",
    "    try:\n",
    "        # Parse the current date\n",
    "        current_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        \n",
    "        # Calculate the lookback and lookahead dates\n",
    "        lookback_date = current_date - timedelta(days=1)\n",
    "        lookahead_date = current_date + timedelta(days=35)\n",
    "        \n",
    "        # Format dates for the SQL query\n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_current_date = current_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Loop through each longitude range\n",
    "        for i in range(len(sorted_lons) + 1):\n",
    "            if i == 0:\n",
    "                min_lon = sorted_lons[i] - buffer_value\n",
    "                max_lon = sorted_lons[i]\n",
    "            elif i == len(sorted_lons):\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i - 1] + buffer_value\n",
    "            else:\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i]\n",
    "            \n",
    "            # Construct the SQL query\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id, \n",
    "                event_zoned_datetime, \n",
    "                processing_date,\n",
    "                lat,\n",
    "                lng\n",
    "            FROM {pe_dl_table}\n",
    "            WHERE \n",
    "                processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "                AND country_code = '{country_code}' \n",
    "                AND event_zoned_datetime IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "                AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "                AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "            \n",
    "            try:\n",
    "                pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "                \n",
    "                # Convert the generator to a DataFrame\n",
    "                chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "                if chunks:\n",
    "                    pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                    \n",
    "                    # Calculate geohashes\n",
    "                    pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                    \n",
    "                    # Aggregate data for geohash3\n",
    "                    aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                        no_of_points=('geohash3', 'size'),\n",
    "                        no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Filter rows with no_of_unique_users > 10\n",
    "                    filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                    \n",
    "                    # Add the local_date column\n",
    "                    filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                    \n",
    "                    # Save filtered aggregated data for geohash3 to CSV file\n",
    "                    if not filtered_data_3.empty:\n",
    "                        csv_filename = f\"/home/jovyan/Data/Fixing/pd_{country_code.lower()}_fix_agg3_2.csv\"\n",
    "                        filtered_data_3.to_csv(csv_filename, mode='a', index=False, header=not pd.io.common.file_exists(csv_filename))\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "                failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2046050-9ff8-4ced-bafa-83be8aa0f56d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 19:53:42,463 - INFO - Executing SQL query for date 20191224 and longitude range 47.5 to 67.5\n",
      "2024-07-02 19:54:00,062 - ERROR - Error while processing data for date 20191224 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 19:54:00,062 - INFO - Executing SQL query for date 20191224 and longitude range 67.5 to 68.90625\n",
      "2024-07-02 19:55:01,796 - INFO - Executing SQL query for date 20191224 and longitude range 68.90625 to 70.3125\n",
      "2024-07-02 19:55:58,104 - INFO - Executing SQL query for date 20191224 and longitude range 70.3125 to 71.71875\n",
      "2024-07-02 19:57:31,571 - INFO - Executing SQL query for date 20191224 and longitude range 71.71875 to 73.125\n",
      "2024-07-02 19:59:43,656 - INFO - Executing SQL query for date 20191224 and longitude range 73.125 to 74.53125\n",
      "2024-07-02 20:01:48,195 - INFO - Executing SQL query for date 20191224 and longitude range 74.53125 to 75.9375\n",
      "2024-07-02 20:03:24,111 - INFO - Executing SQL query for date 20191224 and longitude range 75.9375 to 77.34375\n",
      "2024-07-02 20:05:56,787 - INFO - Executing SQL query for date 20191224 and longitude range 77.34375 to 78.75\n",
      "2024-07-02 20:08:28,904 - INFO - Executing SQL query for date 20191224 and longitude range 78.75 to 80.15625\n",
      "2024-07-02 20:09:34,055 - INFO - Executing SQL query for date 20191224 and longitude range 80.15625 to 81.5625\n",
      "2024-07-02 20:10:56,232 - INFO - Executing SQL query for date 20191224 and longitude range 81.5625 to 82.96875\n",
      "2024-07-02 20:11:50,771 - INFO - Executing SQL query for date 20191224 and longitude range 82.96875 to 84.375\n",
      "2024-07-02 20:12:30,394 - INFO - Executing SQL query for date 20191224 and longitude range 84.375 to 85.78125\n",
      "2024-07-02 20:13:09,413 - INFO - Executing SQL query for date 20191224 and longitude range 85.78125 to 87.1875\n",
      "2024-07-02 20:14:08,019 - INFO - Executing SQL query for date 20191224 and longitude range 87.1875 to 88.59375\n",
      "2024-07-02 20:15:13,482 - INFO - Executing SQL query for date 20191224 and longitude range 88.59375 to 108.59375\n",
      "2024-07-02 20:16:05,367 - INFO - Executing SQL query for date 20191226 and longitude range 47.5 to 67.5\n",
      "2024-07-02 20:16:15,167 - ERROR - Error while processing data for date 20191226 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 20:16:15,168 - INFO - Executing SQL query for date 20191226 and longitude range 67.5 to 68.90625\n",
      "2024-07-02 20:17:13,378 - INFO - Executing SQL query for date 20191226 and longitude range 68.90625 to 70.3125\n",
      "2024-07-02 20:18:10,098 - INFO - Executing SQL query for date 20191226 and longitude range 70.3125 to 71.71875\n",
      "2024-07-02 20:19:49,710 - INFO - Executing SQL query for date 20191226 and longitude range 71.71875 to 73.125\n",
      "2024-07-02 20:22:14,206 - INFO - Executing SQL query for date 20191226 and longitude range 73.125 to 74.53125\n",
      "2024-07-02 20:24:13,414 - INFO - Executing SQL query for date 20191226 and longitude range 74.53125 to 75.9375\n",
      "2024-07-02 20:25:56,227 - INFO - Executing SQL query for date 20191226 and longitude range 75.9375 to 77.34375\n",
      "2024-07-02 20:28:57,022 - INFO - Executing SQL query for date 20191226 and longitude range 77.34375 to 78.75\n",
      "2024-07-02 20:31:37,297 - INFO - Executing SQL query for date 20191226 and longitude range 78.75 to 80.15625\n",
      "2024-07-02 20:33:09,732 - INFO - Executing SQL query for date 20191226 and longitude range 80.15625 to 81.5625\n",
      "2024-07-02 20:34:51,013 - INFO - Executing SQL query for date 20191226 and longitude range 81.5625 to 82.96875\n",
      "2024-07-02 20:36:10,910 - INFO - Executing SQL query for date 20191226 and longitude range 82.96875 to 84.375\n",
      "2024-07-02 20:37:32,567 - INFO - Executing SQL query for date 20191226 and longitude range 84.375 to 85.78125\n",
      "2024-07-02 20:39:01,999 - INFO - Executing SQL query for date 20191226 and longitude range 85.78125 to 87.1875\n",
      "2024-07-02 20:40:10,607 - INFO - Executing SQL query for date 20191226 and longitude range 87.1875 to 88.59375\n",
      "2024-07-02 20:41:34,977 - INFO - Executing SQL query for date 20191226 and longitude range 88.59375 to 108.59375\n",
      "2024-07-02 20:42:13,485 - INFO - failed after 3 attempts\n",
      "2024-07-02 20:42:15,033 - INFO - failed after 3 attempts\n",
      "2024-07-02 20:42:15,034 - ERROR - Error closing cursor\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py\", line 365, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 501, in execute\n",
      "    self._iterator = iter(self._query.execute())\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 821, in execute\n",
      "    self._result.rows += self.fetch()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 838, in fetch\n",
      "    status = self._request.process(response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 617, in process\n",
      "    self.raise_response_error(http_response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 600, in raise_response_error\n",
      "    raise exceptions.Http502Error(\"error 502: bad gateway\")\n",
      "trino.exceptions.Http502Error: error 502: bad gateway\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1995, in _safe_close_cursor\n",
      "    cursor.close()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 618, in close\n",
      "    self.cancel()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 615, in cancel\n",
      "    self._query.cancel()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 862, in cancel\n",
      "    self._request.raise_response_error(response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 600, in raise_response_error\n",
      "    raise exceptions.Http502Error(\"error 502: bad gateway\")\n",
      "trino.exceptions.Http502Error: error 502: bad gateway\n",
      "2024-07-02 20:42:15,035 - ERROR - Error while processing data for date 20191226 and longitude range 88.59375 to 108.59375: error 502: bad gateway\n",
      "2024-07-02 20:42:15,035 - INFO - Executing SQL query for date 20190525 and longitude range 47.5 to 67.5\n",
      "2024-07-02 20:43:07,237 - ERROR - Error while processing data for date 20190525 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 20:43:07,238 - INFO - Executing SQL query for date 20190525 and longitude range 67.5 to 68.90625\n",
      "2024-07-02 20:44:36,822 - INFO - Executing SQL query for date 20190525 and longitude range 68.90625 to 70.3125\n",
      "2024-07-02 20:46:01,523 - INFO - Executing SQL query for date 20190525 and longitude range 70.3125 to 71.71875\n",
      "2024-07-02 20:47:49,525 - INFO - Executing SQL query for date 20190525 and longitude range 71.71875 to 73.125\n",
      "2024-07-02 20:50:49,882 - INFO - Executing SQL query for date 20190525 and longitude range 73.125 to 74.53125\n",
      "2024-07-02 20:53:14,268 - INFO - Executing SQL query for date 20190525 and longitude range 74.53125 to 75.9375\n",
      "2024-07-02 20:56:12,364 - INFO - Executing SQL query for date 20190525 and longitude range 75.9375 to 77.34375\n",
      "2024-07-02 21:00:24,961 - INFO - Executing SQL query for date 20190525 and longitude range 77.34375 to 78.75\n",
      "2024-07-02 21:03:38,787 - INFO - Executing SQL query for date 20190525 and longitude range 78.75 to 80.15625\n",
      "2024-07-02 21:05:41,267 - INFO - Executing SQL query for date 20190525 and longitude range 80.15625 to 81.5625\n",
      "2024-07-02 21:07:58,172 - INFO - Executing SQL query for date 20190525 and longitude range 81.5625 to 82.96875\n",
      "2024-07-02 21:09:12,396 - INFO - Executing SQL query for date 20190525 and longitude range 82.96875 to 84.375\n",
      "2024-07-02 21:10:52,854 - INFO - Executing SQL query for date 20190525 and longitude range 84.375 to 85.78125\n",
      "2024-07-02 21:11:55,382 - INFO - Executing SQL query for date 20190525 and longitude range 85.78125 to 87.1875\n",
      "2024-07-02 21:13:53,716 - INFO - Executing SQL query for date 20190525 and longitude range 87.1875 to 88.59375\n",
      "2024-07-02 21:14:30,085 - INFO - failed after 3 attempts\n",
      "2024-07-02 21:14:31,458 - INFO - failed after 3 attempts\n",
      "2024-07-02 21:14:31,459 - ERROR - Error closing cursor\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py\", line 365, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 501, in execute\n",
      "    self._iterator = iter(self._query.execute())\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 821, in execute\n",
      "    self._result.rows += self.fetch()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 838, in fetch\n",
      "    status = self._request.process(response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 617, in process\n",
      "    self.raise_response_error(http_response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 600, in raise_response_error\n",
      "    raise exceptions.Http502Error(\"error 502: bad gateway\")\n",
      "trino.exceptions.Http502Error: error 502: bad gateway\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1995, in _safe_close_cursor\n",
      "    cursor.close()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 618, in close\n",
      "    self.cancel()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 615, in cancel\n",
      "    self._query.cancel()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 862, in cancel\n",
      "    self._request.raise_response_error(response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 600, in raise_response_error\n",
      "    raise exceptions.Http502Error(\"error 502: bad gateway\")\n",
      "trino.exceptions.Http502Error: error 502: bad gateway\n",
      "2024-07-02 21:14:31,460 - ERROR - Error while processing data for date 20190525 and longitude range 87.1875 to 88.59375: error 502: bad gateway\n",
      "2024-07-02 21:14:31,461 - INFO - Executing SQL query for date 20190525 and longitude range 88.59375 to 108.59375\n",
      "2024-07-02 21:14:32,407 - INFO - failed after 3 attempts\n",
      "2024-07-02 21:14:32,408 - ERROR - Error closing cursor\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py\", line 365, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 482, in execute\n",
      "    self._prepare_statement(operation, statement_name)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 379, in _prepare_statement\n",
      "    query.execute()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 807, in execute\n",
      "    status = self._request.process(response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 617, in process\n",
      "    self.raise_response_error(http_response)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/client.py\", line 600, in raise_response_error\n",
      "    raise exceptions.Http502Error(\"error 502: bad gateway\")\n",
      "trino.exceptions.Http502Error: error 502: bad gateway\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 1995, in _safe_close_cursor\n",
      "    cursor.close()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 618, in close\n",
      "    self.cancel()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.9/site-packages/trino/dbapi.py\", line 612, in cancel\n",
      "    raise trino.exceptions.OperationalError(\n",
      "trino.exceptions.OperationalError: Cancel query failed; no running query\n",
      "2024-07-02 21:16:50,627 - INFO - Executing SQL query for date 20191014 and longitude range 47.5 to 67.5\n",
      "2024-07-02 21:16:59,203 - ERROR - Error while processing data for date 20191014 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 21:16:59,204 - INFO - Executing SQL query for date 20191014 and longitude range 67.5 to 68.90625\n",
      "2024-07-02 21:17:24,864 - INFO - Executing SQL query for date 20191014 and longitude range 68.90625 to 70.3125\n",
      "2024-07-02 21:18:04,226 - INFO - Executing SQL query for date 20191014 and longitude range 70.3125 to 71.71875\n",
      "2024-07-02 21:18:55,416 - INFO - Executing SQL query for date 20191014 and longitude range 71.71875 to 73.125\n",
      "2024-07-02 21:20:26,388 - INFO - Executing SQL query for date 20191014 and longitude range 73.125 to 74.53125\n",
      "2024-07-02 21:21:34,286 - INFO - Executing SQL query for date 20191014 and longitude range 74.53125 to 75.9375\n",
      "2024-07-02 21:23:27,391 - INFO - Executing SQL query for date 20191014 and longitude range 75.9375 to 77.34375\n",
      "2024-07-02 21:25:58,657 - INFO - Executing SQL query for date 20191014 and longitude range 77.34375 to 78.75\n",
      "2024-07-02 21:27:58,744 - INFO - Executing SQL query for date 20191014 and longitude range 78.75 to 80.15625\n",
      "2024-07-02 21:29:06,348 - INFO - Executing SQL query for date 20191014 and longitude range 80.15625 to 81.5625\n",
      "2024-07-02 21:30:41,226 - INFO - Executing SQL query for date 20191014 and longitude range 81.5625 to 82.96875\n",
      "2024-07-02 21:31:29,097 - INFO - Executing SQL query for date 20191014 and longitude range 82.96875 to 84.375\n",
      "2024-07-02 21:32:38,289 - INFO - Executing SQL query for date 20191014 and longitude range 84.375 to 85.78125\n",
      "2024-07-02 21:33:25,396 - INFO - Executing SQL query for date 20191014 and longitude range 85.78125 to 87.1875\n",
      "2024-07-02 21:35:08,182 - INFO - Executing SQL query for date 20191014 and longitude range 87.1875 to 88.59375\n",
      "2024-07-02 21:36:19,966 - INFO - Executing SQL query for date 20191014 and longitude range 88.59375 to 108.59375\n",
      "2024-07-02 21:37:52,046 - INFO - Executing SQL query for date 20190522 and longitude range 47.5 to 67.5\n",
      "2024-07-02 21:38:02,105 - ERROR - Error while processing data for date 20190522 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-07-02 21:38:02,106 - INFO - Executing SQL query for date 20190522 and longitude range 67.5 to 68.90625\n",
      "2024-07-02 21:39:09,384 - INFO - Executing SQL query for date 20190522 and longitude range 68.90625 to 70.3125\n",
      "2024-07-02 21:40:10,967 - INFO - Executing SQL query for date 20190522 and longitude range 70.3125 to 71.71875\n",
      "2024-07-02 21:42:16,410 - INFO - Executing SQL query for date 20190522 and longitude range 71.71875 to 73.125\n"
     ]
    }
   ],
   "source": [
    "# Define the specific dates to run the script\n",
    "specific_dates = ['20191224', '20191226', '20190525', '20191014', '20190522']\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize a list to store failed inserts\n",
    "failed_inserts = []\n",
    "\n",
    "# Loop through each specific date\n",
    "for date_str in specific_dates:\n",
    "    try:\n",
    "        # Parse the current date\n",
    "        current_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        \n",
    "        # Calculate the lookback and lookahead dates\n",
    "        lookback_date = current_date - timedelta(days=1)\n",
    "        lookahead_date = current_date + timedelta(days=35)\n",
    "        \n",
    "        # Format dates for the SQL query\n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_current_date = current_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Loop through each longitude range\n",
    "        for i in range(len(sorted_lons) + 1):\n",
    "            if i == 0:\n",
    "                min_lon = sorted_lons[i] - buffer_value\n",
    "                max_lon = sorted_lons[i]\n",
    "            elif i == len(sorted_lons):\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i - 1] + buffer_value\n",
    "            else:\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i]\n",
    "            \n",
    "            # Construct the SQL query\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id, \n",
    "                event_zoned_datetime, \n",
    "                processing_date,\n",
    "                lat,\n",
    "                lng\n",
    "            FROM {pe_dl_table}\n",
    "            WHERE \n",
    "                processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "                AND country_code = '{country_code}' \n",
    "                AND event_zoned_datetime IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "                AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "                AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "            \n",
    "            try:\n",
    "                pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "                \n",
    "                # Convert the generator to a DataFrame\n",
    "                chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "                if chunks:\n",
    "                    pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                    \n",
    "                    # Calculate geohashes\n",
    "                    pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                    \n",
    "                    # Aggregate data for geohash3\n",
    "                    aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                        no_of_points=('geohash3', 'size'),\n",
    "                        no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Filter rows with no_of_unique_users > 10\n",
    "                    filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                    \n",
    "                    # Add the local_date column\n",
    "                    filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                    \n",
    "                    # Save filtered aggregated data for geohash3 to CSV file\n",
    "                    if not filtered_data_3.empty:\n",
    "                        csv_filename = f\"/home/jovyan/Data/Fixing/pd_{country_code.lower()}_fix_agg3_2.csv\"\n",
    "                        filtered_data_3.to_csv(csv_filename, mode='a', index=False, header=not pd.io.common.file_exists(csv_filename))\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "                failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9d37a-2fe2-4603-8495-acb9b19fd3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a0f81-3aeb-40e6-8482-eab9a6d9b08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec702ba-5e73-49f6-b3e3-62d1205abb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94340697-be4b-4859-9d83-e289ad99e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash3</th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>local_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tdk</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tds</td>\n",
       "      <td>32656</td>\n",
       "      <td>796</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tdu</td>\n",
       "      <td>75673</td>\n",
       "      <td>1574</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teh</td>\n",
       "      <td>36127</td>\n",
       "      <td>844</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tek</td>\n",
       "      <td>293023</td>\n",
       "      <td>6308</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>whe</td>\n",
       "      <td>5601</td>\n",
       "      <td>158</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>whf</td>\n",
       "      <td>11756</td>\n",
       "      <td>290</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>whg</td>\n",
       "      <td>32171</td>\n",
       "      <td>696</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>whu</td>\n",
       "      <td>6001</td>\n",
       "      <td>128</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>wjh</td>\n",
       "      <td>234</td>\n",
       "      <td>12</td>\n",
       "      <td>20191126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    geohash3  no_of_points  no_of_unique_users local_date\n",
       "0        tdk           188                  13   20191126\n",
       "1        tds         32656                 796   20191126\n",
       "2        tdu         75673                1574   20191126\n",
       "3        teh         36127                 844   20191126\n",
       "4        tek        293023                6308   20191126\n",
       "..       ...           ...                 ...        ...\n",
       "167      whe          5601                 158   20191126\n",
       "168      whf         11756                 290   20191126\n",
       "169      whg         32171                 696   20191126\n",
       "170      whu          6001                 128   20191126\n",
       "171      wjh           234                  12   20191126\n",
       "\n",
       "[172 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM dedicated.pop_density.pd_in_20191126_agg3_2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "pe_dl_table_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be496d42-7289-45ff-874c-8475a0bcad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_dl_table_gen.to_csv('/home/jovyan/Data/Fixing/pd_in_20191126_agg3_2.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76205176-dcfb-40da-a43b-5de537dc8b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5798c-7fb3-42fb-a178-23f34e6b7f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd1280-7aa1-44ab-b3f5-20bbe269a147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56511083-c91b-427e-b1b5-841f36b17ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
