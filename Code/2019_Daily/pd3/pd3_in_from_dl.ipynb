{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d289ed9b-b5c6-42f8-9b8a-8d2653a94f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%config SqlMagic.autolimit=0\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaylimit=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7304cfd6-5f4e-4fd1-9fcb-e4f799127977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @cuebiq/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql trino://localhost:9090/cuebiq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ccb1e3-ccad-4833-b2fd-3646480078ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geohash2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geohash2) (0.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geohash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d54996b-6d6c-475c-ad0a-0d895f41ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import geohash2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe46e82-6e2f-463e-b61d-c09c017bf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2185a185-453b-4e44-88ed-cccba705c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data with retry mechanism\n",
    "def insert_data_with_retry(df, table_name, con, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                con, \n",
    "                index=False, \n",
    "                if_exists=\"append\", \n",
    "                method=\"multi\"\n",
    "            )\n",
    "            logging.info(f\"Inserted data into table {table_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(f\"Failed to insert data into table {table_name} after {retries} attempts\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1706be65-38bc-40c2-a13c-07032a38ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'IN'\n",
    "start_date = 20190825\n",
    "end_date = 20190825\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\"\n",
    "\n",
    "# Convert integer dates to datetime objects\n",
    "start_date_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "end_date_dt = datetime.strptime(str(end_date), '%Y%m%d')\n",
    "\n",
    "# Define the sorted longitude boundaries\n",
    "sorted_lons = [67.5, 68.90625, 70.3125, 71.71875, 73.125, \n",
    "               74.53125, 75.9375, 77.34375, 78.75, 80.15625, \n",
    "               81.5625, 82.96875, 84.375, 85.78125, 87.1875, \n",
    "               88.59375]\n",
    "\n",
    "# Initialize a list to store failed insertions\n",
    "failed_inserts = []\n",
    "# Define the buffer value\n",
    "buffer_value = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "148ea67f-8013-4887-867f-4f30f018dc5a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:49:21,144 - INFO - Executing SQL query for date 20190825 and longitude range 47.5 to 67.5\n",
      "2024-06-15 01:49:29,455 - ERROR - Error while processing data for date 20190825 and longitude range 47.5 to 67.5: cannot set a frame with no defined index and a scalar\n",
      "2024-06-15 01:49:29,456 - INFO - Executing SQL query for date 20190825 and longitude range 67.5 to 68.90625\n",
      "2024-06-15 01:49:59,831 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:49:59,832 - INFO - Executing SQL query for date 20190825 and longitude range 68.90625 to 70.3125\n",
      "2024-06-15 01:50:36,766 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:50:36,767 - INFO - Executing SQL query for date 20190825 and longitude range 70.3125 to 71.71875\n",
      "2024-06-15 01:51:16,448 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:51:16,449 - INFO - Executing SQL query for date 20190825 and longitude range 71.71875 to 73.125\n",
      "2024-06-15 01:53:06,609 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:53:06,610 - INFO - Executing SQL query for date 20190825 and longitude range 73.125 to 74.53125\n",
      "2024-06-15 01:54:28,835 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:54:28,836 - INFO - Executing SQL query for date 20190825 and longitude range 74.53125 to 75.9375\n",
      "2024-06-15 01:56:11,481 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:56:11,481 - INFO - Executing SQL query for date 20190825 and longitude range 75.9375 to 77.34375\n",
      "2024-06-15 01:58:48,733 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 01:58:48,734 - INFO - Executing SQL query for date 20190825 and longitude range 77.34375 to 78.75\n",
      "2024-06-15 02:01:10,203 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:01:10,203 - INFO - Executing SQL query for date 20190825 and longitude range 78.75 to 80.15625\n",
      "2024-06-15 02:02:26,092 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:02:26,092 - INFO - Executing SQL query for date 20190825 and longitude range 80.15625 to 81.5625\n",
      "2024-06-15 02:03:35,243 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:03:35,244 - INFO - Executing SQL query for date 20190825 and longitude range 81.5625 to 82.96875\n",
      "2024-06-15 02:04:25,310 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:04:25,311 - INFO - Executing SQL query for date 20190825 and longitude range 82.96875 to 84.375\n",
      "2024-06-15 02:05:14,421 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:05:14,422 - INFO - Executing SQL query for date 20190825 and longitude range 84.375 to 85.78125\n",
      "2024-06-15 02:06:04,914 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:06:04,914 - INFO - Executing SQL query for date 20190825 and longitude range 85.78125 to 87.1875\n",
      "2024-06-15 02:06:55,179 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:06:55,179 - INFO - Executing SQL query for date 20190825 and longitude range 87.1875 to 88.59375\n",
      "2024-06-15 02:08:00,923 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:08:00,923 - INFO - Executing SQL query for date 20190825 and longitude range 88.59375 to 108.59375\n",
      "2024-06-15 02:08:56,295 - INFO - Inserted data into table pd_in_20190825_agg3\n",
      "2024-06-15 02:08:56,296 - INFO - Data extraction, aggregation, and saving completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed inserts:\n",
      "('20190825', 47.5, 67.5)\n"
     ]
    }
   ],
   "source": [
    "# Loop through each day from start_date to end_date\n",
    "current_date = start_date_dt\n",
    "while current_date <= end_date_dt:\n",
    "    try:\n",
    "        # Calculate the lookback and lookahead dates\n",
    "        lookback_date = current_date - timedelta(days=1)\n",
    "        lookahead_date = current_date + timedelta(days=35)\n",
    "        \n",
    "        # Format dates for the SQL query\n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_current_date = current_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        # Loop through each longitude range\n",
    "        for i in range(len(sorted_lons) + 1):\n",
    "            if i == 0:\n",
    "                min_lon = sorted_lons[i] - buffer_value\n",
    "                max_lon = sorted_lons[i]\n",
    "            elif i == len(sorted_lons):\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i - 1] + buffer_value\n",
    "            else:\n",
    "                min_lon = sorted_lons[i - 1]\n",
    "                max_lon = sorted_lons[i]\n",
    "            \n",
    "            # Construct the SQL query\n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id, \n",
    "                event_zoned_datetime, \n",
    "                processing_date,\n",
    "                lat,\n",
    "                lng\n",
    "            FROM {pe_dl_table}\n",
    "            WHERE \n",
    "                processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "                AND country_code = '{country_code}' \n",
    "                AND event_zoned_datetime IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "                AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "                AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "            \"\"\"\n",
    "            \n",
    "            logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "            \n",
    "            try:\n",
    "                pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "                \n",
    "                # Convert the generator to a DataFrame\n",
    "                chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "                if chunks:\n",
    "                    pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                    \n",
    "                    # Calculate geohashes\n",
    "                    pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                    \n",
    "                    # Aggregate data for geohash3\n",
    "                    aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                        no_of_points=('geohash3', 'size'),\n",
    "                        no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Filter rows with no_of_unique_users > 10\n",
    "                    filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                    \n",
    "                    # Add the local_date column\n",
    "                    filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                    \n",
    "                    # Insert filtered aggregated data for geohash3 into SQL table\n",
    "                    if not filtered_data_3.empty:\n",
    "                        table_name_agg3 = f\"pd_{country_code.lower()}_{formatted_current_date}_agg3\"\n",
    "                        if not insert_data_with_retry(filtered_data_3, table_name_agg3, con):\n",
    "                            failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "                failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n",
    "    \n",
    "    # Move to the next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9acd1-22f1-4d35-adb5-e3c7cc97b38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38845288-a751-406b-aa05-2f614fc729b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c793941-1c1c-428f-96d3-1780253886ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9467a-19fa-484b-b17a-a69b4754c265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ddd88-ecd7-4e2d-8644-c23c7a4a8e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ed585-830c-4d5b-9e12-f981b1e987cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8d5db-61f3-4a52-bb71-95108bf4d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2e7e0d-733e-44a1-b396-40e14e75c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize the SQL engine\n",
    "sql_engine = TrinoEngine()\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "# Define the buffer value\n",
    "buffer_value = 20\n",
    "failed_inserts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1599829-fd47-4e09-bee4-2bb7bb18f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data for a given date and longitude range\n",
    "def process_data_for_date_and_lon(formatted_current_date, min_lon, max_lon):\n",
    "    try:\n",
    "        lookback_date = datetime.strptime(formatted_current_date, '%Y%m%d') - timedelta(days=1)\n",
    "        lookahead_date = datetime.strptime(formatted_current_date, '%Y%m%d') + timedelta(days=35)\n",
    "        \n",
    "        formatted_lookback_date = lookback_date.strftime('%Y%m%d')\n",
    "        formatted_lookahead_date = lookahead_date.strftime('%Y%m%d')\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            cuebiq_id, \n",
    "            event_zoned_datetime, \n",
    "            processing_date,\n",
    "            lat,\n",
    "            lng\n",
    "        FROM cuebiq.paas_cda_pe_v3.device_location_uplevelled\n",
    "        WHERE \n",
    "            processing_date BETWEEN {formatted_lookback_date} AND {formatted_lookahead_date}\n",
    "            AND country_code = '{country_code}' \n",
    "            AND event_zoned_datetime IS NOT NULL\n",
    "            AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "            AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) = date_parse('{formatted_current_date}', '%Y%m%d')\n",
    "            AND lng BETWEEN {min_lon} AND {max_lon}\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info(f\"Executing SQL query for date {formatted_current_date} and longitude range {min_lon} to {max_lon}\")\n",
    "        \n",
    "        try:\n",
    "            pe_dl_table_gen = sql_engine.read_sql_chunked(query)\n",
    "            \n",
    "            chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "            if chunks:\n",
    "                pe_dl_table_df = pd.concat(chunks, ignore_index=True)\n",
    "                \n",
    "                pe_dl_table_df['geohash3'] = pe_dl_table_df.apply(lambda row: geohash2.encode(row['lat'], row['lng'], precision=3), axis=1)\n",
    "                \n",
    "                aggregated_data_3 = pe_dl_table_df.groupby('geohash3').agg(\n",
    "                    no_of_points=('geohash3', 'size'),\n",
    "                    no_of_unique_users=('cuebiq_id', 'nunique')\n",
    "                ).reset_index()\n",
    "                \n",
    "                filtered_data_3 = aggregated_data_3[aggregated_data_3['no_of_unique_users'] > 10].copy()\n",
    "                \n",
    "                filtered_data_3.loc[:, 'local_date'] = formatted_current_date\n",
    "                \n",
    "                if not filtered_data_3.empty:\n",
    "                    table_name_agg3 = f\"pd_{country_code.lower()}_{formatted_current_date}_agg3\"\n",
    "                    if not insert_data_with_retry(filtered_data_3, table_name_agg3, con):\n",
    "                        failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while processing data for date {formatted_current_date} and longitude range {min_lon} to {max_lon}: {e}\")\n",
    "            failed_inserts.append((formatted_current_date, min_lon, max_lon))\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while processing data for date {formatted_current_date}: {e}\")\n",
    "        failed_inserts.append((formatted_current_date, None, None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e239e-b566-4eaf-aba7-65eb0552cbfd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:47:20,183 - INFO - Executing SQL query for date 20190603 and longitude range 73.125 to 74.53125\n",
      "2024-06-13 22:48:28,948 - INFO - Inserted data into table pd_in_20190603_agg3\n",
      "2024-06-13 22:48:29,020 - INFO - Executing SQL query for date 20190620 and longitude range 87.1875 to 88.59375\n",
      "2024-06-13 22:49:25,742 - INFO - Inserted data into table pd_in_20190620_agg3\n",
      "2024-06-13 22:49:25,797 - INFO - Executing SQL query for date 20190620 and longitude range 88.59375 to 108.59375\n",
      "2024-06-13 22:50:08,892 - INFO - Inserted data into table pd_in_20190620_agg3\n",
      "2024-06-13 22:50:08,928 - INFO - Executing SQL query for date 20190715 and longitude range 71.71875 to 73.125\n",
      "2024-06-13 22:51:37,198 - INFO - Inserted data into table pd_in_20190715_agg3\n",
      "2024-06-13 22:51:37,304 - INFO - Executing SQL query for date 20190721 and longitude range 88.59375 to 108.59375\n",
      "2024-06-13 22:52:19,114 - INFO - Inserted data into table pd_in_20190721_agg3\n",
      "2024-06-13 22:52:19,145 - INFO - Executing SQL query for date 20190723 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 22:54:36,292 - INFO - Inserted data into table pd_in_20190723_agg3\n",
      "2024-06-13 22:54:36,471 - INFO - Executing SQL query for date 20190723 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 22:56:35,221 - INFO - Inserted data into table pd_in_20190723_agg3\n",
      "2024-06-13 22:56:35,370 - INFO - Executing SQL query for date 20190724 and longitude range 80.15625 to 81.5625\n",
      "2024-06-13 22:57:28,857 - INFO - Inserted data into table pd_in_20190724_agg3\n",
      "2024-06-13 22:57:28,906 - INFO - Executing SQL query for date 20190724 and longitude range 81.5625 to 82.96875\n",
      "2024-06-13 22:58:06,361 - INFO - Inserted data into table pd_in_20190724_agg3\n",
      "2024-06-13 22:58:06,384 - INFO - Executing SQL query for date 20190731 and longitude range 67.5 to 68.90625\n",
      "2024-06-13 22:58:27,489 - INFO - Inserted data into table pd_in_20190731_agg3\n",
      "2024-06-13 22:58:27,490 - INFO - Executing SQL query for date 20190801 and longitude range 73.125 to 74.53125\n",
      "2024-06-13 22:59:33,715 - INFO - Inserted data into table pd_in_20190801_agg3\n",
      "2024-06-13 22:59:33,782 - INFO - Executing SQL query for date 20190801 and longitude range 74.53125 to 75.9375\n",
      "2024-06-13 23:01:03,275 - INFO - Inserted data into table pd_in_20190801_agg3\n",
      "2024-06-13 23:01:03,377 - INFO - Executing SQL query for date 20190804 and longitude range 82.96875 to 84.375\n",
      "2024-06-13 23:01:43,310 - INFO - Inserted data into table pd_in_20190804_agg3\n",
      "2024-06-13 23:01:43,333 - INFO - Executing SQL query for date 20190804 and longitude range 84.375 to 85.78125\n",
      "2024-06-13 23:02:21,824 - INFO - Inserted data into table pd_in_20190804_agg3\n",
      "2024-06-13 23:02:21,854 - INFO - Executing SQL query for date 20190808 and longitude range 78.75 to 80.15625\n",
      "2024-06-13 23:03:22,087 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:03:22,145 - INFO - Executing SQL query for date 20190808 and longitude range 80.15625 to 81.5625\n",
      "2024-06-13 23:04:17,367 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:04:17,417 - INFO - Executing SQL query for date 20190808 and longitude range 81.5625 to 82.96875\n",
      "2024-06-13 23:04:54,242 - INFO - Inserted data into table pd_in_20190808_agg3\n",
      "2024-06-13 23:04:54,265 - INFO - Executing SQL query for date 20190812 and longitude range 71.71875 to 73.125\n",
      "2024-06-13 23:06:29,107 - INFO - Inserted data into table pd_in_20190812_agg3\n",
      "2024-06-13 23:06:29,213 - INFO - Executing SQL query for date 20190815 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 23:08:31,910 - INFO - Inserted data into table pd_in_20190815_agg3\n",
      "2024-06-13 23:08:32,063 - INFO - Executing SQL query for date 20190815 and longitude range 78.75 to 80.15625\n",
      "2024-06-13 23:09:34,368 - INFO - Inserted data into table pd_in_20190815_agg3\n",
      "2024-06-13 23:09:34,430 - INFO - Executing SQL query for date 20190820 and longitude range 67.5 to 68.90625\n",
      "2024-06-13 23:09:54,904 - INFO - Inserted data into table pd_in_20190820_agg3\n",
      "2024-06-13 23:09:54,905 - INFO - Executing SQL query for date 20190821 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 23:12:13,985 - INFO - Inserted data into table pd_in_20190821_agg3\n",
      "2024-06-13 23:12:14,164 - INFO - Executing SQL query for date 20190824 and longitude range 75.9375 to 77.34375\n",
      "2024-06-13 23:14:31,670 - INFO - Inserted data into table pd_in_20190824_agg3\n",
      "2024-06-13 23:14:31,850 - INFO - Executing SQL query for date 20190824 and longitude range 77.34375 to 78.75\n",
      "2024-06-13 23:16:31,769 - INFO - Inserted data into table pd_in_20190824_agg3\n",
      "2024-06-13 23:16:31,926 - INFO - Data extraction, aggregation, and saving completed for missing sections.\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters\n",
    "country_code = 'IN'\n",
    "missing_sections = [\n",
    "    ('20190603', 73.125, 74.53125),\n",
    "    ('20190620', 87.1875, 88.59375),\n",
    "    ('20190620', 88.59375, 108.59375),\n",
    "    ('20190715', 71.71875, 73.125),\n",
    "    ('20190721', 88.59375, 108.59375),\n",
    "    ('20190723', 75.9375, 77.34375),\n",
    "    ('20190723', 77.34375, 78.75),\n",
    "    ('20190724', 80.15625, 81.5625),\n",
    "    ('20190724', 81.5625, 82.96875),\n",
    "    ('20190731', 67.5, 68.90625),\n",
    "    ('20190801', 73.125, 74.53125),\n",
    "    ('20190801', 74.53125, 75.9375),\n",
    "    ('20190804', 82.96875, 84.375),\n",
    "    ('20190804', 84.375, 85.78125),\n",
    "    ('20190808', 78.75, 80.15625),\n",
    "    ('20190808', 80.15625, 81.5625),\n",
    "    ('20190808', 81.5625, 82.96875),\n",
    "    ('20190812', 71.71875, 73.125),\n",
    "    ('20190815', 77.34375, 78.75),\n",
    "    ('20190815', 78.75, 80.15625),\n",
    "    ('20190820', 67.5, 68.90625),\n",
    "    ('20190821', 75.9375, 77.34375),\n",
    "    ('20190824', 75.9375, 77.34375),\n",
    "    ('20190824', 77.34375, 78.75)\n",
    "]\n",
    "\n",
    "# Loop through each missing section\n",
    "for section in missing_sections:\n",
    "    formatted_current_date, min_lon, max_lon = section\n",
    "    process_data_for_date_and_lon(formatted_current_date, min_lon, max_lon)\n",
    "\n",
    "# Print the failed inserts\n",
    "if failed_inserts:\n",
    "    print(\"Failed inserts:\")\n",
    "    for failed_insert in failed_inserts:\n",
    "        print(failed_insert)\n",
    "\n",
    "logging.info(\"Data extraction, aggregation, and saving completed for missing sections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56511083-c91b-427e-b1b5-841f36b17ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
