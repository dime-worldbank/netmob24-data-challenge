{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e12420-8683-4154-a7f5-88d98d4528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b2ec24-24c0-4a8e-acdb-501f288d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8a785e-275c-4379-ba11-3f3841dfe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'MX'\n",
    "country_code = 'CO'\n",
    "#country_code = 'IN'\n",
    "#start_date = 20190101\n",
    "#end_date = 20190131\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\"\n",
    "\n",
    "# Convert integer dates to datetime objects\n",
    "#start_date_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "#end_date_dt = datetime.strptime(str(end_date), '%Y%m%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9786e035-b5d2-4cc3-863f-9f8f6a92d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_date = start_date_dt\n",
    "popDensity_threshold = 10\n",
    "pathFolder = \"./popDensity/3h/{}/2020/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#formatted_current_date = current_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ee85a5-dbb1-4fe4-83a8-5b83eb7b2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kanonimization (fileName,popDensity_threshold):\n",
    "    df = pd.read_csv(fileName)\n",
    "    print (\"Before k-anonimity {}\".format(df.shape[0]))\n",
    "    #cols = ['ind','popDensity', 'hour', 'day', 'month', 'geohash5']\n",
    "    #df.columns = cols\n",
    "    df = df[ df['popDensity'] >= popDensity_threshold ]\n",
    "    print (\"After k-anonimity {}\".format(df.shape[0]))\n",
    "    df[['popDensity', 'grt', 'day', 'month', 'geohash5']].to_csv(fileName+'_kanonnimized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0917f-54e2-48aa-bb22-4e8e1d39030a",
   "metadata": {},
   "source": [
    "# Convert the generator to a DataFrame\n",
    "chunks = [chunk for chunk in pe_dl_table_gen]\n",
    "pe_dl_table_df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdf2a8-186b-4da5-8318-da8a9fcd500e",
   "metadata": {},
   "source": [
    "## January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31a29a9-1081-45ba-8605-8d268a0622e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 784044\n",
      "After k-anonimity 112619\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200101', '%Y%m%d') AND date_parse('20200131', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jan.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb8737-a0fb-404b-b9ed-74b40d2d3ed8",
   "metadata": {},
   "source": [
    "# February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea080452-b180-4216-b8df-b95b080bea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 635254\n",
      "After k-anonimity 86485\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200201', '%Y%m%d') AND date_parse('20200228', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_feb.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90546ca-1901-4e54-ae41-6111d3991d60",
   "metadata": {},
   "source": [
    "## March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c747d38-3e35-4e35-b135-7a734c9db27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 654441\n",
      "After k-anonimity 80545\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200301', '%Y%m%d') AND date_parse('20200331', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_mar.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1a670-21d8-4fc3-8c74-ce19ec4f0458",
   "metadata": {},
   "source": [
    "# April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164bf31-504e-4d26-bddf-a5e45b511338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200401', '%Y%m%d') AND date_parse('20200430', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_apr.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561570-050c-4557-9358-897405d2f940",
   "metadata": {},
   "source": [
    "# May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ff01-40a2-4925-9ae7-ea1d92989a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200501', '%Y%m%d') AND date_parse('20200531', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_may.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214da338-6732-459b-aaaf-4398c7772087",
   "metadata": {},
   "source": [
    "# Jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163b5cc-e270-40d6-a2bf-d4fe9f0ffeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200601', '%Y%m%d') AND date_parse('20200630', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jun.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3587-d771-4821-a0f4-15f9cb6d6a69",
   "metadata": {},
   "source": [
    "# July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1f566-367a-4601-bac8-402acb76b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200701', '%Y%m%d') AND date_parse('20200731', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jul.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d240a-6657-460e-80c4-a392c3a1b48a",
   "metadata": {},
   "source": [
    "# August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e46a-d995-49dd-9759-38e043f5344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200801', '%Y%m%d') AND date_parse('20200831', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_aug.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ee9fb-1699-45ef-9c18-5184d5588af6",
   "metadata": {},
   "source": [
    "# September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94425b-6ac4-42fe-b723-ea6513da9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200901', '%Y%m%d') AND date_parse('20200930', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_set.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391c8c-dadc-4e37-8e11-bdc8d1386c45",
   "metadata": {},
   "source": [
    "# October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57888aba-cb21-4754-90f7-acbbe491da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201001', '%Y%m%d') AND date_parse('20201031', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_oct.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d41ad-f046-4980-9c2c-4cff323200eb",
   "metadata": {},
   "source": [
    "# November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7312d-d666-455f-af6d-1dde05f43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201101', '%Y%m%d') AND date_parse('20201130', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_nov.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d99c18-2bbd-4171-9b09-90922979cce3",
   "metadata": {},
   "source": [
    "# December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850cee5-0a4d-40dd-ae2a-502ea4f65c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT(cuebiq_id))  popDensity,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201201', '%Y%m%d') AND date_parse('20201231', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_dec.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9dd27-e384-4587-b814-29219529664b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5073-e361-4a26-9933-c0722a60bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
