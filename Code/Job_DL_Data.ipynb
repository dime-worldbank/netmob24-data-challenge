{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff9e4df-146c-4120-a8f9-220b7d551c96",
   "metadata": {},
   "source": [
    "Download dl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5aa75d-6b26-48f8-b783-44b0e42e4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8071db6-5131-4ce1-96d4-2f3bb05c2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine\n",
    "from trino.dbapi import connect \n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4658058-9886-417f-b56c-8b09190e1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "\n",
    "# dl_table = f\"{schema_name['cda']}.device_location\"  \n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\"\n",
    "\n",
    "tj_table = f\"{schema_name['cda']}.trajectory\"     \n",
    "pe_tj_table = f\"{schema_name['cda']}.trajectory_uplevelled\"\n",
    "\n",
    "# stop_table = f\"{schema['cda']}.stop\" \n",
    "pe_stop_table = f\"{schema_name['cda']}.stop_uplevelled\"\n",
    "\n",
    "visit_table = f\"{schema_name['cda']}.visit \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccbd66-ded9-406b-bd6b-27773cd5ebdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3259a4e-bddb-486e-b55f-050519bb9085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ecb71-8f95-4e8d-a032-1f3e66d05f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dba29-d5fc-4753-9789-811f6c08fd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4300f4dd-fb7d-4c71-847d-02cf287f07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrinoEngine:\n",
    "    def __init__(self):\n",
    "        self.conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query: str):\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0390c906-4555-4941-910b-6c6f86ba523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing country: MX\n",
      "Processing date: 20190129 for country: MX\n",
      "Processing date: 20190130 for country: MX\n",
      "Processing date: 20190131 for country: MX\n",
      "Finished processing country: MX\n",
      "Total time taken: 1595.3800954818726 seconds\n"
     ]
    }
   ],
   "source": [
    "countries = ['MX']\n",
    "start_date = 20190129\n",
    "end_date = 20190131\n",
    "\n",
    "# Convert integer dates to datetime objects\n",
    "start_date_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "end_date_dt = datetime.strptime(str(end_date), '%Y%m%d')\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "for country_code in countries:\n",
    "    print(f\"Processing country: {country_code}\")\n",
    "    current_date = start_date_dt\n",
    "    while current_date <= end_date_dt:\n",
    "        formatted_date = current_date.strftime('%Y%m%d')\n",
    "        next_date = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        print(f\"Processing date: {formatted_date} for country: {country_code}\")\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id, \n",
    "                event_zoned_datetime, \n",
    "                processing_date,\n",
    "                timezoneoffset_secs,\n",
    "                lat,\n",
    "                lng, \n",
    "                TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s') +\n",
    "                interval '1' second * timezoneoffset_secs) AS event_datetime_utc\n",
    "            FROM {pe_dl_table}\n",
    "            WHERE \n",
    "                processing_date = {formatted_date} \n",
    "                AND country_code = '{country_code}' \n",
    "                AND event_zoned_datetime IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) >= date_parse('{start_date_dt.strftime('%Y%m%d')}', '%Y%m%d')\n",
    "                AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) <= date_parse('{next_date}', '%Y-%m-%d')\n",
    "        \"\"\"\n",
    "\n",
    "        for chunk in sql_engine.read_sql_chunked(query):\n",
    "            # Extract event_zoned_date from event_zoned_datetime\n",
    "            chunk['event_zoned_date'] = chunk['event_zoned_datetime'].apply(lambda x: x[:10])\n",
    "\n",
    "            # Convert processing_date and event_zoned_date to datetime objects\n",
    "            chunk['event_zoned_date'] = pd.to_datetime(chunk['event_zoned_date'])\n",
    "            processing_date_dt = datetime.strptime(formatted_date, '%Y%m%d')\n",
    "\n",
    "            # Filter data based on event_zoned_date\n",
    "            chunk = chunk[(chunk['event_zoned_date'] >= start_date_dt.strftime('%Y-%m-%d')) & \n",
    "                          (chunk['event_zoned_date'] <= processing_date_dt.strftime('%Y-%m-%d'))]\n",
    "\n",
    "            # Group by event_zoned_date\n",
    "            grouped = chunk.groupby('event_zoned_date')\n",
    "\n",
    "            for event_zoned_date, group_df in grouped:\n",
    "                # Remove duplicates\n",
    "                group_df = group_df.drop_duplicates()\n",
    "\n",
    "                # Convert event_zoned_date to string and remove hyphens\n",
    "                event_zoned_date_str = event_zoned_date.strftime('%Y%m%d')\n",
    "                file_path = f'/home/jovyan/Data/DL/{country_code}/{event_zoned_date_str}_{country_code}_pe_dl.csv'\n",
    "\n",
    "                if os.path.exists(file_path):\n",
    "                    # If the file exists, append the new data\n",
    "                    group_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    # If the file does not exist, create it\n",
    "                    try:\n",
    "                        group_df.to_csv(file_path, index=False)\n",
    "                    except OSError as e:\n",
    "                        if not os.path.exists(os.path.dirname(file_path)):\n",
    "                            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "                            group_df.to_csv(file_path, index=False)\n",
    "                        else:\n",
    "                            raise e\n",
    "\n",
    "            # Delete the DataFrame to free up memory\n",
    "            del chunk\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    print(f\"Finished processing country: {country_code}\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the total time taken\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time taken: {total_time} seconds\")\n",
    "\n",
    "\n",
    "# Processing date: 20190114 for country: IN\n",
    "# Processing date: 20190430 for country: ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ed202-4740-4553-8727-aac788b252cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108dc33-0202-4eab-8542-4bf08b3a3a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436063ba-b127-43eb-8820-f114e73f57da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb0731-d516-49ac-9d2c-974c8a2396d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c649a0a-8c9a-4935-bf89-e7d7365f520d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a534b-6da5-4c3a-98e8-d0a4104b5a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfe27c-2e94-4f9b-b468-5b0e9781a262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8205f0-0500-4fcf-9070-edb42522616c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1ace2-e79e-4bc2-a0a7-a9614bbbf02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f8902-2bf8-4668-ab34-7264eeed1ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837c139-d597-413d-b580-432ae9119b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
