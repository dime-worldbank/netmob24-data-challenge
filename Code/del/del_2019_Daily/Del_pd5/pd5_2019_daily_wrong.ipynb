{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e12420-8683-4154-a7f5-88d98d4528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b2ec24-24c0-4a8e-acdb-501f288d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8a785e-275c-4379-ba11-3f3841dfe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'pop_density'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'CO'\n",
    "# country_code = 'MX'\n",
    "# country_code = 'ID'\n",
    "# country_code = 'IN'\n",
    "#start_date = 20190101\n",
    "#end_date = 20190131\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\"\n",
    "\n",
    "# Convert integer dates to datetime objects\n",
    "#start_date_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "#end_date_dt = datetime.strptime(str(end_date), '%Y%m%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9786e035-b5d2-4cc3-863f-9f8f6a92d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_date = start_date_dt\n",
    "popDensity_threshold = 10\n",
    "pathFolder = \"/home/jovyan/Data/daily_pd5/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#formatted_current_date = current_date.strftime('%Y%m%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ee85a5-dbb1-4fe4-83a8-5b83eb7b2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kanonimization (fileName,popDensity_threshold):\n",
    "    df = pd.read_csv(fileName)\n",
    "    print (\"Before k-anonimity {}\".format(df.shape[0]))\n",
    "    df = df[ df['no_of_unique_users'] >= popDensity_threshold ]\n",
    "    print (\"After k-anonimity {}\".format(df.shape[0]))\n",
    "    df[['geohash_5','no_of_points','no_of_unique_users','grt', 'day', 'month']].to_csv(fileName+'_kanonnimized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0917f-54e2-48aa-bb22-4e8e1d39030a",
   "metadata": {},
   "source": [
    "# Convert the generator to a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdf2a8-186b-4da5-8318-da8a9fcd500e",
   "metadata": {},
   "source": [
    "## January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a29a9-1081-45ba-8605-8d268a0622e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190101', '%Y%m%d') AND date_parse('20190131', '%Y%m%d')   \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jan.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98267211-590f-46b3-ac04-a0dcf4469720",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb8737-a0fb-404b-b9ed-74b40d2d3ed8",
   "metadata": {},
   "source": [
    "# February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea080452-b180-4216-b8df-b95b080bea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 1971767\n",
      "After k-anonimity 204845\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200201', '%Y%m%d') AND date_parse('20200229', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_feb_2020.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90546ca-1901-4e54-ae41-6111d3991d60",
   "metadata": {},
   "source": [
    "## March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c747d38-3e35-4e35-b135-7a734c9db27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190301', '%Y%m%d') AND date_parse('20190331', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_mar.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1a670-21d8-4fc3-8c74-ce19ec4f0458",
   "metadata": {},
   "source": [
    "# April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164bf31-504e-4d26-bddf-a5e45b511338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190401', '%Y%m%d') AND date_parse('20190430', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_apr.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561570-050c-4557-9358-897405d2f940",
   "metadata": {},
   "source": [
    "# May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ff01-40a2-4925-9ae7-ea1d92989a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190501', '%Y%m%d') AND date_parse('20190531', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_may.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214da338-6732-459b-aaaf-4398c7772087",
   "metadata": {},
   "source": [
    "# Jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163b5cc-e270-40d6-a2bf-d4fe9f0ffeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190601', '%Y%m%d') AND date_parse('20190630', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jun.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3587-d771-4821-a0f4-15f9cb6d6a69",
   "metadata": {},
   "source": [
    "# July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1f566-367a-4601-bac8-402acb76b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190701', '%Y%m%d') AND date_parse('20190731', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jul.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d240a-6657-460e-80c4-a392c3a1b48a",
   "metadata": {},
   "source": [
    "# August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e46a-d995-49dd-9759-38e043f5344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190801', '%Y%m%d') AND date_parse('20190831', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_aug.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ee9fb-1699-45ef-9c18-5184d5588af6",
   "metadata": {},
   "source": [
    "# September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94425b-6ac4-42fe-b723-ea6513da9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190901', '%Y%m%d') AND date_parse('20190930', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_set.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391c8c-dadc-4e37-8e11-bdc8d1386c45",
   "metadata": {},
   "source": [
    "# October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57888aba-cb21-4754-90f7-acbbe491da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191001', '%Y%m%d') AND date_parse('20191031', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_oct.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d41ad-f046-4980-9c2c-4cff323200eb",
   "metadata": {},
   "source": [
    "# November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b7312d-d666-455f-af6d-1dde05f43fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 816586\n",
      "After k-anonimity 121606\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191101', '%Y%m%d') AND date_parse('20191130', '%Y%m%d') \n",
    "    AND lat <> 0\n",
    "    AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_nov.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d99c18-2bbd-4171-9b09-90922979cce3",
   "metadata": {},
   "source": [
    "# December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4850cee5-0a4d-40dd-ae2a-502ea4f65c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before k-anonimity 747384\n",
      "After k-anonimity 95979\n"
     ]
    }
   ],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    COUNT(cuebiq_id)  no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id))  no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash_5 \n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191201', '%Y%m%d') AND date_parse('20191231', '%Y%m%d') \n",
    "    AND lat <> 0\n",
    "    AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, day, month, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_dec.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5073-e361-4a26-9933-c0722a60bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d8e2e-4d03-4880-bc81-02e466a16524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5ce0e-db6c-4bd8-9fbe-c55347a049f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db46410-a4df-407c-b7a6-6f62e732b4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0524f4-1d21-45eb-b489-dafe54bb9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d16a86-2a2e-42c7-90fe-8970dbe61a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1c7b2-ad42-4625-b770-a4aec6cddca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
