{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e12420-8683-4154-a7f5-88d98d4528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b2ec24-24c0-4a8e-acdb-501f288d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8a785e-275c-4379-ba11-3f3841dfe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'CO'\n",
    "# country_code = 'ID'\n",
    "# country_code = 'IN'\n",
    "# country_code = 'MX'\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9786e035-b5d2-4cc3-863f-9f8f6a92d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFolder = \"/home/jovyan/Data/3h_pd5/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdf2a8-186b-4da5-8318-da8a9fcd500e",
   "metadata": {},
   "source": [
    "# January to March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31a29a9-1081-45ba-8605-8d268a0622e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200101', '%Y%m%d') AND date_parse('20200331', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}13_2020_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d1c204-95d2-4d95-beec-9ced5c1a5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200401', '%Y%m%d') AND date_parse('20200630', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}46_2020_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e3fd2f6-3ffd-4321-baf6-09fd0638a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200701', '%Y%m%d') AND date_parse('20201231', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}712_2020_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7096a66-97ae-4980-8df3-6ebaaf9ed3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f4b4b-d069-489f-9620-2b26d55625b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9f1ab-e971-4258-93d9-7d2e67b178d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190801', '%Y%m%d') AND date_parse('20190831', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}8_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ec1a4-f49a-48b3-85a2-e67e8cee547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190901', '%Y%m%d') AND date_parse('20190930', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}9_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bd159-6199-47d5-83e6-289994ef2b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2ed56-461f-44e0-b426-d135cdc0e432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce6251-9ced-4714-b994-7cf9e96b190e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7e4cbc-1fb5-4cbe-a585-ec24e519b1d6",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad09dfa-7697-4257-965f-ba8a177c4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0b47c7-ddfb-4ad9-9621-470507619974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d753647-235c-4a37-894d-95599d525a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/Data/3h_pd5/MX46_2019_3h_agg5.csv',\n",
       " '/home/jovyan/Data/3h_pd5/MX13_2019_3h_agg5.csv',\n",
       " '/home/jovyan/Data/3h_pd5/MX1012_2019_3h_agg5.csv',\n",
       " '/home/jovyan/Data/3h_pd5/MX79_2019_3h_agg5.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_pattern = '/home/jovyan/Data/3h_pd5/MX*_2019_3h_agg5.csv'\n",
    "file_list = glob.glob(path_pattern)\n",
    "file_sub_list = [path for path in file_list]\n",
    "file_sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212fed81-ed44-46f4-9a3a-3db20076366e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6531</td>\n",
       "      <td>806</td>\n",
       "      <td>6</td>\n",
       "      <td>20190410</td>\n",
       "      <td>9mubu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9eyb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25670</td>\n",
       "      <td>3866</td>\n",
       "      <td>2</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9g3qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6409</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9gbnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9095</td>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "      <td>20190409</td>\n",
       "      <td>9mvct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577299</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20190711</td>\n",
       "      <td>9t7xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20190710</td>\n",
       "      <td>9ss9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577301</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20190709</td>\n",
       "      <td>9te1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20190708</td>\n",
       "      <td>9u94u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577303</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20190709</td>\n",
       "      <td>9mw5j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45577304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 6531                 806    6    20190410     9mubu\n",
       "1                   45                   5    4    20190503     9eyb4\n",
       "2                25670                3866    2    20190503     9g3qw\n",
       "3                 6409                 893    3    20190503     9gbnn\n",
       "4                 9095                 904    5    20190409     9mvct\n",
       "...                ...                 ...  ...         ...       ...\n",
       "45577299             1                   1    2    20190711     9t7xg\n",
       "45577300             1                   1    7    20190710     9ss9d\n",
       "45577301             1                   1    3    20190709     9te1h\n",
       "45577302             2                   1    5    20190708     9u94u\n",
       "45577303             1                   1    3    20190709     9mw5j\n",
       "\n",
       "[45577304 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448f1d8-1b8f-4c2f-9998-428eef1f964e",
   "metadata": {},
   "source": [
    "## Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21bf73c-0b2d-4fe2-8cae-4dbf43328238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6531</td>\n",
       "      <td>806</td>\n",
       "      <td>6</td>\n",
       "      <td>20190410</td>\n",
       "      <td>9mubu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9eyb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25670</td>\n",
       "      <td>3866</td>\n",
       "      <td>2</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9g3qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6409</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9gbnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9095</td>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "      <td>20190409</td>\n",
       "      <td>9mvct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577299</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20190711</td>\n",
       "      <td>9t7xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20190710</td>\n",
       "      <td>9ss9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577301</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20190709</td>\n",
       "      <td>9te1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20190708</td>\n",
       "      <td>9u94u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45577303</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20190709</td>\n",
       "      <td>9mw5j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45577304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 6531                 806    6    20190410     9mubu\n",
       "1                   45                   5    4    20190503     9eyb4\n",
       "2                25670                3866    2    20190503     9g3qw\n",
       "3                 6409                 893    3    20190503     9gbnn\n",
       "4                 9095                 904    5    20190409     9mvct\n",
       "...                ...                 ...  ...         ...       ...\n",
       "45577299             1                   1    2    20190711     9t7xg\n",
       "45577300             1                   1    7    20190710     9ss9d\n",
       "45577301             1                   1    3    20190709     9te1h\n",
       "45577302             2                   1    5    20190708     9u94u\n",
       "45577303             1                   1    3    20190709     9mw5j\n",
       "\n",
       "[45577304 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['geohash_5'] = combined_df['geohash_5'].astype(str)\n",
    "combined_df['no_of_points'] = combined_df['no_of_points'].astype(int)\n",
    "combined_df['no_of_unique_users'] = combined_df['no_of_unique_users'].astype(int)\n",
    "combined_df['local_date'] = combined_df['local_date'].astype(int)\n",
    "\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fe3ec-2018-4204-921d-0ab2aa4d2028",
   "metadata": {},
   "source": [
    "## Check missing date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503d3b85-9904-46fc-9c29-59caf7b2b3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_count = combined_df[\"local_date\"].unique()\n",
    "all_dates = pd.date_range(start='2019-01-01', end='2019-12-31').strftime('%Y%m%d').astype(int)\n",
    "all_dates = np.array(all_dates)\n",
    "missing_dates = np.setdiff1d(all_dates, unique_values_count)\n",
    "\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839eda4-7591-4c6c-961c-949ef9179ac4",
   "metadata": {},
   "source": [
    "## Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690bffcd-c0b4-4ad8-858e-fd5be3ed5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6531</td>\n",
       "      <td>806</td>\n",
       "      <td>6</td>\n",
       "      <td>20190410</td>\n",
       "      <td>9mubu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25670</td>\n",
       "      <td>3866</td>\n",
       "      <td>2</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9g3qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6409</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9gbnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9095</td>\n",
       "      <td>904</td>\n",
       "      <td>5</td>\n",
       "      <td>20190409</td>\n",
       "      <td>9mvct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>241</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9u2pe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45427994</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>20190925</td>\n",
       "      <td>9mv1n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45437107</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>20190817</td>\n",
       "      <td>d59ju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463380</th>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>20190706</td>\n",
       "      <td>9mx3g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45521494</th>\n",
       "      <td>113</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>20190707</td>\n",
       "      <td>9mu8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45537354</th>\n",
       "      <td>166</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>20190830</td>\n",
       "      <td>9msz5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9580341 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 6531                 806    6    20190410     9mubu\n",
       "2                25670                3866    2    20190503     9g3qw\n",
       "3                 6409                 893    3    20190503     9gbnn\n",
       "4                 9095                 904    5    20190409     9mvct\n",
       "5                  241                  46    5    20190503     9u2pe\n",
       "...                ...                 ...  ...         ...       ...\n",
       "45427994            27                  10    3    20190925     9mv1n\n",
       "45437107            88                  10    4    20190817     d59ju\n",
       "45463380            69                  10    7    20190706     9mx3g\n",
       "45521494           113                  11    7    20190707     9mu8w\n",
       "45537354           166                  12    0    20190830     9msz5\n",
       "\n",
       "[9580341 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_10 = combined_df[combined_df['no_of_unique_users'] >= 10]\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549e44e-d718-4286-9500-a6cb10587537",
   "metadata": {},
   "source": [
    "## Check with figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a7c34-243b-40b4-9d79-a4b3462a2aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebee9c-eebf-4e36-a869-b70695137122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d4b29-b335-4ff4-b7ee-cc997485d5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e2e9076-c0b1-4aaa-b96a-04dc25189933",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5786cdb-b2ae-4652-8eb1-1b3e1aee0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate local_time based on grt\n",
    "def calculate_local_time(local_date, grt):\n",
    "    start_hour = grt * 3\n",
    "    end_hour = start_hour + 3\n",
    "    return f\"{str(local_date)} {str(start_hour).zfill(2)}:00:00 - {str(end_hour).zfill(2)}:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de7652a-fdd5-4bec-9b6e-273f3ee75546",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_579/2217125973.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df_10.loc[:, 'local_time'] = combined_df_10.apply(lambda row: calculate_local_time(row['local_date'], row['grt']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "      <th>local_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6531</td>\n",
       "      <td>806</td>\n",
       "      <td>20190410</td>\n",
       "      <td>9mubu</td>\n",
       "      <td>20190410 18:00:00 - 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25670</td>\n",
       "      <td>3866</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9g3qw</td>\n",
       "      <td>20190503 06:00:00 - 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6409</td>\n",
       "      <td>893</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9gbnn</td>\n",
       "      <td>20190503 09:00:00 - 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9095</td>\n",
       "      <td>904</td>\n",
       "      <td>20190409</td>\n",
       "      <td>9mvct</td>\n",
       "      <td>20190409 15:00:00 - 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>241</td>\n",
       "      <td>46</td>\n",
       "      <td>20190503</td>\n",
       "      <td>9u2pe</td>\n",
       "      <td>20190503 15:00:00 - 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45427994</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>20190925</td>\n",
       "      <td>9mv1n</td>\n",
       "      <td>20190925 09:00:00 - 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45437107</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>20190817</td>\n",
       "      <td>d59ju</td>\n",
       "      <td>20190817 12:00:00 - 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463380</th>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>20190706</td>\n",
       "      <td>9mx3g</td>\n",
       "      <td>20190706 21:00:00 - 24:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45521494</th>\n",
       "      <td>113</td>\n",
       "      <td>11</td>\n",
       "      <td>20190707</td>\n",
       "      <td>9mu8w</td>\n",
       "      <td>20190707 21:00:00 - 24:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45537354</th>\n",
       "      <td>166</td>\n",
       "      <td>12</td>\n",
       "      <td>20190830</td>\n",
       "      <td>9msz5</td>\n",
       "      <td>20190830 00:00:00 - 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9580341 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          no_of_points  no_of_unique_users  local_date geohash_5  \\\n",
       "0                 6531                 806    20190410     9mubu   \n",
       "2                25670                3866    20190503     9g3qw   \n",
       "3                 6409                 893    20190503     9gbnn   \n",
       "4                 9095                 904    20190409     9mvct   \n",
       "5                  241                  46    20190503     9u2pe   \n",
       "...                ...                 ...         ...       ...   \n",
       "45427994            27                  10    20190925     9mv1n   \n",
       "45437107            88                  10    20190817     d59ju   \n",
       "45463380            69                  10    20190706     9mx3g   \n",
       "45521494           113                  11    20190707     9mu8w   \n",
       "45537354           166                  12    20190830     9msz5   \n",
       "\n",
       "                            local_time  \n",
       "0         20190410 18:00:00 - 21:00:00  \n",
       "2         20190503 06:00:00 - 09:00:00  \n",
       "3         20190503 09:00:00 - 12:00:00  \n",
       "4         20190409 15:00:00 - 18:00:00  \n",
       "5         20190503 15:00:00 - 18:00:00  \n",
       "...                                ...  \n",
       "45427994  20190925 09:00:00 - 12:00:00  \n",
       "45437107  20190817 12:00:00 - 15:00:00  \n",
       "45463380  20190706 21:00:00 - 24:00:00  \n",
       "45521494  20190707 21:00:00 - 24:00:00  \n",
       "45537354  20190830 00:00:00 - 03:00:00  \n",
       "\n",
       "[9580341 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_10.loc[:, 'local_time'] = combined_df_10.apply(lambda row: calculate_local_time(row['local_date'], row['grt']), axis=1)\n",
    "combined_df_10 = combined_df_10.drop(columns=['grt'])\n",
    "\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c783cdee-f3f8-48f6-8020-7eb8f0f2df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "folder_path = '/home/jovyan/Data/3h_pd5/Clean/'\n",
    "combined_df_10.to_csv(folder_path + 'pd_3h_gh5_mx_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60754415-e11a-466b-9d7b-45f90bf8c43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7312d-d666-455f-af6d-1dde05f43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201101', '%Y%m%d') AND date_parse('20201130', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_nov.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850cee5-0a4d-40dd-ae2a-502ea4f65c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201201', '%Y%m%d') AND date_parse('20201231', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_dec.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9dd27-e384-4587-b814-29219529664b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5073-e361-4a26-9933-c0722a60bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
