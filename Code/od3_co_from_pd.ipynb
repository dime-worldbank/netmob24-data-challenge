{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac80492-7321-4716-9eb6-480a39e423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%config SqlMagic.autolimit=0\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaylimit=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb53c70-0bcd-42db-b993-22c1e27621c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @cuebiq/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql trino://localhost:9090/cuebiq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb085d33-6d88-45c7-8157-b6117b60533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-geohash in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.8.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9ead77-7643-4b96-833e-1727f453930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geohash\n",
    "from datetime import datetime, timedelta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0bd797a-04e3-4191-9761-96e660fd396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine\n",
    "from trino.dbapi import connect \n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d583b13b-220f-4219-be2f-439cf2c1c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_tj_table = f\"{schema_name['cda']}.trajectory_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9771058-c43d-4cf3-97eb-3f91d2ca61ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:33:20,454 - INFO - Inserted data into table od_id_20190103_agg3\n",
      "2024-06-05 19:33:38,937 - INFO - Inserted data into table od_id_20190104_agg3\n",
      "2024-06-05 19:33:56,798 - INFO - Inserted data into table od_id_20190105_agg3\n",
      "2024-06-05 19:33:56,799 - INFO - Total processing time: 50.62 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geohash\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection setup\n",
    "output_schema_name = 'od_matrix'\n",
    "con = create_engine(f\"trino://localhost:9090/dedicated/{output_schema_name}\")\n",
    "\n",
    "# Function to process data for a single day\n",
    "def process_day(event_date, country_code, sql_engine):\n",
    "    try:\n",
    "        # Read data from the SQL table\n",
    "        pe_tj_df = sql_engine.read_sql(\n",
    "            f\"\"\"\n",
    "            SELECT \n",
    "                cuebiq_id,\n",
    "                start_lat,\n",
    "                start_lng,\n",
    "                end_lat,\n",
    "                end_lng,\n",
    "                duration_minutes,\n",
    "                length_meters,\n",
    "                number_of_points\n",
    "            FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "            WHERE \n",
    "                event_date = {event_date}\n",
    "                AND end_country = '{country_code}' \n",
    "                AND start_country = '{country_code}' \n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Encode geohashes\n",
    "        pe_tj_df['start_geohash3'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=3), axis=1)\n",
    "        pe_tj_df['end_geohash3'] = pe_tj_df.apply(\n",
    "            lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=3), axis=1)\n",
    "\n",
    "        # Load cell lists from SQL\n",
    "        try:\n",
    "            celllist3 = sql_engine.read_sql(f\"SELECT geohash3 AS geohash, no_of_unique_users FROM dedicated.pop_density.pd_{country_code}_{event_date}_agg3\")\n",
    "            geohash_dict3 = celllist3.set_index('geohash')['no_of_unique_users'].to_dict()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load geohash3 data for date {event_date}: {e}\")\n",
    "            geohash_dict3 = {}\n",
    "\n",
    "        # Add user numbers to the aggregated data\n",
    "        aggregated_df3 = pe_tj_df.groupby(['start_geohash3', 'end_geohash3']).agg({\n",
    "            'cuebiq_id': 'count',\n",
    "            'duration_minutes': ['mean', 'median', 'std'],\n",
    "            'length_meters': ['mean', 'median', 'std'],\n",
    "            'number_of_points': ['mean', 'median', 'std']\n",
    "        }).reset_index()\n",
    "        aggregated_df3.columns = ['start_geohash3', 'end_geohash3', 'trip_count', \n",
    "                                  'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                                  'm_length_m', 'mdn_length_m', 'sd_length_m',\n",
    "                                  'm_points_no', 'mdn_points_no', 'sd_points_no']\n",
    "        aggregated_df3['start_geohash_user'] = aggregated_df3['start_geohash3'].map(geohash_dict3)\n",
    "        aggregated_df3['end_geohash_user'] = aggregated_df3['end_geohash3'].map(geohash_dict3)\n",
    "\n",
    "        # Filter aggregated data and reorder columns\n",
    "        filtered_df3 = aggregated_df3.dropna(subset=['start_geohash_user', 'end_geohash_user'])\n",
    "        filtered_df3 = filtered_df3[['start_geohash3', 'start_geohash_user', 'end_geohash3', 'end_geohash_user', 'trip_count', \n",
    "                                     'm_duration_min', 'mdn_duration_min', 'sd_duration_min', \n",
    "                                     'm_length_m', 'mdn_length_m', 'sd_length_m',\n",
    "                                     'm_points_no', 'mdn_points_no', 'sd_points_no']]\n",
    "        return filtered_df3\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing data for date {event_date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to insert data with retry mechanism\n",
    "def insert_data_with_retry(df, table_name, con, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                con, \n",
    "                index=False, \n",
    "                if_exists=\"append\", \n",
    "                method=\"multi\"\n",
    "            )\n",
    "            logging.info(f\"Inserted data into table {table_name}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(f\"Failed to insert data into table {table_name} after {retries} attempts\")\n",
    "\n",
    "# Main processing loop\n",
    "def process_date_range(start_date, end_date, country_code, sql_engine):\n",
    "    start_time = time.time()  # Record start time before processing loop\n",
    "        \n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        event_date = current_date.strftime('%Y%m%d')\n",
    "        \n",
    "        filtered_df3 = process_day(event_date, country_code, sql_engine)\n",
    "\n",
    "        # Insert data into the database\n",
    "        if not filtered_df3.empty:\n",
    "            table_name = f\"od_{country_code.lower()}_{event_date}_agg3\"\n",
    "            insert_data_with_retry(filtered_df3, table_name, con)\n",
    "        else:\n",
    "            logging.info(f\"No data to insert for date {event_date}\")\n",
    "\n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "    end_time = time.time()  # Record end time after processing loop\n",
    "    total_time = end_time - start_time\n",
    "    logging.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Example usage:\n",
    "process_date_range(datetime(2019, 10, 1), datetime(2019, 12, 31), 'CO', sql_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3e50b-3390-4d93-8953-694fed314694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6379754-4724-4e7b-8c53-1be5b6b989b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuebiq_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>length_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2717518640</td>\n",
       "      <td>3.436203</td>\n",
       "      <td>-76.540658</td>\n",
       "      <td>3.367047</td>\n",
       "      <td>-76.529736</td>\n",
       "      <td>178.216667</td>\n",
       "      <td>9072.208487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2717518640</td>\n",
       "      <td>3.367047</td>\n",
       "      <td>-76.529736</td>\n",
       "      <td>3.436122</td>\n",
       "      <td>-76.540637</td>\n",
       "      <td>80.083333</td>\n",
       "      <td>8189.523241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2717483025</td>\n",
       "      <td>10.963962</td>\n",
       "      <td>-74.840365</td>\n",
       "      <td>10.964186</td>\n",
       "      <td>-74.841364</td>\n",
       "      <td>173.116667</td>\n",
       "      <td>534.865058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2717377552</td>\n",
       "      <td>7.876402</td>\n",
       "      <td>-76.627072</td>\n",
       "      <td>7.878519</td>\n",
       "      <td>-76.626878</td>\n",
       "      <td>219.016667</td>\n",
       "      <td>2326.635493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2717377552</td>\n",
       "      <td>7.878519</td>\n",
       "      <td>-76.626878</td>\n",
       "      <td>7.876418</td>\n",
       "      <td>-76.627134</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>235.592936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134755</th>\n",
       "      <td>2267573244</td>\n",
       "      <td>11.019228</td>\n",
       "      <td>-74.817414</td>\n",
       "      <td>11.005213</td>\n",
       "      <td>-74.826734</td>\n",
       "      <td>14.183333</td>\n",
       "      <td>2609.690248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134756</th>\n",
       "      <td>2267573244</td>\n",
       "      <td>11.005213</td>\n",
       "      <td>-74.826734</td>\n",
       "      <td>11.005883</td>\n",
       "      <td>-74.818957</td>\n",
       "      <td>14.816667</td>\n",
       "      <td>918.411412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134757</th>\n",
       "      <td>1540926349</td>\n",
       "      <td>9.578892</td>\n",
       "      <td>-73.471045</td>\n",
       "      <td>9.578242</td>\n",
       "      <td>-73.466186</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>739.410094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134758</th>\n",
       "      <td>1540926349</td>\n",
       "      <td>9.578242</td>\n",
       "      <td>-73.466186</td>\n",
       "      <td>9.578323</td>\n",
       "      <td>-73.466123</td>\n",
       "      <td>297.933333</td>\n",
       "      <td>2283.671544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134759</th>\n",
       "      <td>1540926349</td>\n",
       "      <td>9.578323</td>\n",
       "      <td>-73.466123</td>\n",
       "      <td>9.578875</td>\n",
       "      <td>-73.470996</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>678.901537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134760 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cuebiq_id  start_lat  start_lng    end_lat    end_lng  \\\n",
       "0       2717518640   3.436203 -76.540658   3.367047 -76.529736   \n",
       "1       2717518640   3.367047 -76.529736   3.436122 -76.540637   \n",
       "2       2717483025  10.963962 -74.840365  10.964186 -74.841364   \n",
       "3       2717377552   7.876402 -76.627072   7.878519 -76.626878   \n",
       "4       2717377552   7.878519 -76.626878   7.876418 -76.627134   \n",
       "...            ...        ...        ...        ...        ...   \n",
       "134755  2267573244  11.019228 -74.817414  11.005213 -74.826734   \n",
       "134756  2267573244  11.005213 -74.826734  11.005883 -74.818957   \n",
       "134757  1540926349   9.578892 -73.471045   9.578242 -73.466186   \n",
       "134758  1540926349   9.578242 -73.466186   9.578323 -73.466123   \n",
       "134759  1540926349   9.578323 -73.466123   9.578875 -73.470996   \n",
       "\n",
       "        duration_minutes  length_meters  \n",
       "0             178.216667    9072.208487  \n",
       "1              80.083333    8189.523241  \n",
       "2             173.116667     534.865058  \n",
       "3             219.016667    2326.635493  \n",
       "4              22.100000     235.592936  \n",
       "...                  ...            ...  \n",
       "134755         14.183333    2609.690248  \n",
       "134756         14.816667     918.411412  \n",
       "134757         51.500000     739.410094  \n",
       "134758        297.933333    2283.671544  \n",
       "134759         13.350000     678.901537  \n",
       "\n",
       "[134760 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_date = 20191113\n",
    "country_code = 'CO'\n",
    "\n",
    "pe_tj_df = sql_engine.read_sql(\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "        cuebiq_id,\n",
    "        start_lat,\n",
    "        start_lng,\n",
    "        end_lat,\n",
    "        end_lng,\n",
    "        duration_minutes,\n",
    "        length_meters\n",
    "    FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "    WHERE \n",
    "        event_date = {event_date}\n",
    "        AND end_country = '{country_code}' \n",
    "        AND start_country = '{country_code}' \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Encode geohashes\n",
    "pe_tj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee057d6-d59a-487c-943b-cf9bae55db3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805934c-d7ba-4e1d-b8f3-36386e66ea59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed79e1b-7955-48f7-bb3f-7f850aeab25a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:12:47,973 - INFO - File saved to /home/jovyan/Data/Agg_TJ/ID3/20190101_ID_pe_tj_agg3.csv\n",
      "2024-06-05 19:12:58,782 - INFO - File saved to /home/jovyan/Data/Agg_TJ/ID3/20190102_ID_pe_tj_agg3.csv\n",
      "2024-06-05 19:13:13,316 - INFO - File saved to /home/jovyan/Data/Agg_TJ/ID3/20190103_ID_pe_tj_agg3.csv\n",
      "2024-06-05 19:13:29,895 - INFO - File saved to /home/jovyan/Data/Agg_TJ/ID3/20190104_ID_pe_tj_agg3.csv\n",
      "2024-06-05 19:13:44,626 - INFO - File saved to /home/jovyan/Data/Agg_TJ/ID3/20190105_ID_pe_tj_agg3.csv\n",
      "2024-06-05 19:13:44,626 - INFO - Total processing time: 68.74 seconds\n"
     ]
    }
   ],
   "source": [
    "# # save as .csv to the system, only 3\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import geohash\n",
    "# from datetime import datetime, timedelta\n",
    "# import logging\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Function to process data for a single day\n",
    "# def process_day(event_date, country_code, sql_engine):\n",
    "#     try:\n",
    "#         # Read data from the SQL table\n",
    "#         pe_tj_df = sql_engine.read_sql(\n",
    "#             f\"\"\"\n",
    "#             SELECT \n",
    "#                 cuebiq_id,\n",
    "#                 start_lat,\n",
    "#                 start_lng,\n",
    "#                 end_lat,\n",
    "#                 end_lng,\n",
    "#                 duration_minutes,\n",
    "#                 length_meters\n",
    "#             FROM cuebiq.paas_cda_pe_v3.trajectory_uplevelled\n",
    "#             WHERE \n",
    "#                 event_date = {event_date}\n",
    "#                 AND end_country = '{country_code}' \n",
    "#                 AND start_country = '{country_code}' \n",
    "#             \"\"\"\n",
    "#         )\n",
    "\n",
    "#         # Encode geohashes\n",
    "#         pe_tj_df['start_geohash3'] = pe_tj_df.apply(\n",
    "#             lambda x: geohash.encode(x['start_lat'], x['start_lng'], precision=3), axis=1)\n",
    "#         pe_tj_df['end_geohash3'] = pe_tj_df.apply(\n",
    "#             lambda x: geohash.encode(x['end_lat'], x['end_lng'], precision=3), axis=1)\n",
    "\n",
    "#         # Load cell lists from SQL\n",
    "#         try:\n",
    "#             celllist3 = sql_engine.read_sql(f\"SELECT geohash3 AS geohash, no_of_unique_users FROM dedicated.pop_density.pd_{country_code}_{event_date}_agg3\")\n",
    "#             geohash_dict3 = celllist3.set_index('geohash')['no_of_unique_users'].to_dict()\n",
    "#         except Exception as e:\n",
    "#             logging.warning(f\"Failed to load geohash3 data for date {event_date}: {e}\")\n",
    "#             geohash_dict3 = {}\n",
    "\n",
    "#         # Add user numbers to the aggregated data\n",
    "#         aggregated_df3 = pe_tj_df.groupby(['start_geohash3', 'end_geohash3']).agg({\n",
    "#             'cuebiq_id': 'count',\n",
    "#             'duration_minutes': ['mean', 'median', 'std'],\n",
    "#             'length_meters': ['mean', 'median', 'std']\n",
    "#         }).reset_index()\n",
    "#         aggregated_df3.columns = ['start_geohash3', 'end_geohash3', 'trip_count', 'm_duration_min', 'mdn_duration_min', 'sd_duration_min', 'm_length_m', 'mdn_length_m', 'sd_length_m']\n",
    "#         aggregated_df3['start_geohash_user'] = aggregated_df3['start_geohash3'].map(geohash_dict3)\n",
    "#         aggregated_df3['end_geohash_user'] = aggregated_df3['end_geohash3'].map(geohash_dict3)\n",
    "\n",
    "#         # Filter aggregated data\n",
    "#         filtered_df3 = aggregated_df3.dropna(subset=['start_geohash_user', 'end_geohash_user'])\n",
    "\n",
    "#         # Reorder columns\n",
    "#         filtered_df3 = filtered_df3[['start_geohash3', 'start_geohash_user', 'end_geohash3', 'end_geohash_user', 'trip_count', 'm_duration_min', 'mdn_duration_min', 'sd_duration_min', 'm_length_m', 'mdn_length_m', 'sd_length_m']]\n",
    "\n",
    "#         return filtered_df3\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error processing data for date {event_date}: {e}\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# # Main processing loop\n",
    "# def process_date_range(start_date, end_date, country_code, sql_engine):\n",
    "#     start_time = time.time()  # Record start time before processing loop\n",
    "        \n",
    "#     current_date = start_date\n",
    "#     while current_date <= end_date:\n",
    "#         event_date = current_date.strftime('%Y%m%d')\n",
    "        \n",
    "#         filtered_df3 = process_day(event_date, country_code, sql_engine)\n",
    "\n",
    "#         # Define file path\n",
    "#         file_path_3 = f'/home/jovyan/Data/Agg_TJ/{country_code}3/{event_date}_{country_code}_pe_tj_agg3.csv'\n",
    "\n",
    "#         # Save results if data is not empty and file does not already exist\n",
    "#         if not filtered_df3.empty and not os.path.exists(file_path_3):\n",
    "#             os.makedirs(os.path.dirname(file_path_3), exist_ok=True)\n",
    "#             filtered_df3.to_csv(file_path_3, index=False)\n",
    "#             logging.info(f\"File saved to {file_path_3}\")\n",
    "#         else:\n",
    "#             logging.info(f\"File already exists or no data for {file_path_3}\")\n",
    "\n",
    "#         # Move to the next day\n",
    "#         current_date += timedelta(days=1)\n",
    "#     end_time = time.time()  # Record end time after processing loop\n",
    "#     total_time = end_time - start_time\n",
    "#     logging.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "\n",
    "# # Example usage:\n",
    "# process_date_range(datetime(2019, 1, 1), datetime(2019, 1, 5), 'ID', sql_engine)\n",
    "\n",
    "# # worked save as .csv to the system, only 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159c211-e0a9-4aa3-8f88-931269922469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20b8d0-be7b-44e6-95a5-ba70650ede5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4db05-2639-4d55-adae-fec758f9c97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150d96e-8311-4268-9172-a6fa7f5ba1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe55a9-be17-4357-862e-c09c797397e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a779f-0b84-40f8-a379-acf4490e1a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
