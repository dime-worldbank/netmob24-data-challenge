{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1476f1e-866d-4b64-ac21-e4926523e178",
   "metadata": {},
   "source": [
    "This code should work for pd GH3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e12420-8683-4154-a7f5-88d98d4528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2ec24-24c0-4a8e-acdb-501f288d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a785e-275c-4379-ba11-3f3841dfe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the input parameters\n",
    "# country_code = 'CO'\n",
    "# country_code = 'ID'\n",
    "# country_code = 'IN'\n",
    "country_code = 'MX'\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786e035-b5d2-4cc3-863f-9f8f6a92d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFolder = \"/home/jovyan/Data/3h_pd3/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdf2a8-186b-4da5-8318-da8a9fcd500e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1661f3b-ad3b-437d-9a5e-86b95cd097dc",
   "metadata": {},
   "source": [
    "## January - April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a29a9-1081-45ba-8605-8d268a0622e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200101', '%Y%m%d') AND date_parse('20200430', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}14_2020_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc1fb2-dc08-46ec-ad72-e9f3547036ca",
   "metadata": {},
   "source": [
    "## May - August "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292fa1d-41d7-4320-b87c-b59ec38c728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200501', '%Y%m%d') AND date_parse('20200831', '%Y%m%d') \n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"  \n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}58_2020_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b625dcf-dfeb-4e0e-a754-91aacc7024a5",
   "metadata": {},
   "source": [
    "## September - December "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa583ee-d4a6-4a10-91dd-681378225f51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200901', '%Y%m%d') AND date_parse('20201231', '%Y%m%d') \n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}912_2020_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4b29a-8f65-41ab-a497-c1679a13c863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "425c24b4-29eb-4cb7-adb7-bc6236f06c27",
   "metadata": {},
   "source": [
    "# 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6621c-e804-445f-beb2-dcc7e12662e1",
   "metadata": {},
   "source": [
    "## January - April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734d347-f12f-42f5-b383-7b22f42322e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190101', '%Y%m%d') AND date_parse('20190430', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}14_2019_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0839e-7514-498b-8c23-78bd770ecd3c",
   "metadata": {},
   "source": [
    "## May - August "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576f521-6c5a-4b4e-8181-9f54aee97e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190501', '%Y%m%d') AND date_parse('20190831', '%Y%m%d') \n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"  \n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}58_2019_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023a149-41f8-448e-9320-ab017d898a77",
   "metadata": {},
   "source": [
    "## September - December "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367bd13-4cec-42f7-a347-c121159d0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_3\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 3) AS geohash_3, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190901', '%Y%m%d') AND date_parse('20191231', '%Y%m%d') \n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    ")\n",
    "GROUP BY grt, local_date, geohash_3\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}912_2019_3h_agg3.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a95bc-9314-4b61-913e-36e718fb200d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5f619-fe24-489d-8f7d-45fe0e53c235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19ef7ecf-5aa1-40d0-8062-c311e52539d0",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28eed8d-741b-4f9a-91a0-909d84546295",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2e275-9309-4476-a60e-e362ed3b17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1ff8e-6d4c-473e-89bf-7392f812fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pattern = '/home/jovyan/Data/3h_pd3/IN*_2019_3h_agg3.csv'\n",
    "file_list = glob.glob(path_pattern)\n",
    "file_sub_list = [path for path in file_list]\n",
    "file_sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa77e54-d3e1-47b5-b51f-823743520c82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "# Loop through the list of files and read each file into a DataFrame\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2ec6e-1403-4519-82fb-bc908db5abca",
   "metadata": {},
   "source": [
    "## Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed870c75-55bd-4ffe-9cff-a8ad43265807",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df['geohash_3'] = combined_df['geohash_3'].astype(str)\n",
    "combined_df['no_of_points'] = combined_df['no_of_points'].astype(int)\n",
    "combined_df['no_of_unique_users'] = combined_df['no_of_unique_users'].astype(int)\n",
    "combined_df['local_date'] = combined_df['local_date'].astype(int)\n",
    "\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff79f0b-bf3c-4c79-ba7b-3e7c1a18a105",
   "metadata": {},
   "source": [
    "## Check missing date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06259056-f950-40cf-8878-6065a1ba5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_count = combined_df[\"local_date\"].unique()\n",
    "all_dates = pd.date_range(start='2019-11-01', end='2019-12-31').strftime('%Y%m%d').astype(int)\n",
    "all_dates = np.array(all_dates)\n",
    "missing_dates = np.setdiff1d(all_dates, unique_values_count)\n",
    "\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a1a87-220e-47a2-9bad-dfc08ad81608",
   "metadata": {},
   "source": [
    "## Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4dd5c3-db5a-41e5-a9b6-8c4094755174",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_10 = combined_df[combined_df['no_of_unique_users'] >= 10]\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de3b25-f380-43f0-abf0-be5689689da5",
   "metadata": {},
   "source": [
    "## Check with figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36334e5b-f6ca-43ab-9ce9-3a7e977f8f82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregating the DataFrame by local_date\n",
    "aggregated_df = combined_df_10.groupby('local_date').agg({\n",
    "    'no_of_points': 'sum',\n",
    "    'no_of_unique_users': 'sum',\n",
    "    'geohash_3': ['nunique', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "aggregated_df.columns = ['local_date', 'total_no_of_points', 'total_no_of_unique_users', 'unique_geohash_3', 'sum_geohash_3']\n",
    "aggregated_df['local_date'] = aggregated_df['local_date'].astype(str)\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82fb07-5158-4d35-b2bb-9d98a6ce6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: total_no_of_points and total_no_of_unique_users\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=aggregated_df, x='local_date', y='total_no_of_unique_users', marker='o', label='Total no_of_unique_users')\n",
    "plt.title('Total Unique Users Over Time')\n",
    "plt.xlabel('Local Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d51b6-be62-4b9a-b7f7-436d528dedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: total_no_of_points and total_no_of_unique_users\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=aggregated_df, x='local_date', y='total_no_of_points', marker='o', label='Total no_of_points')\n",
    "plt.title('Total Points Over Time')\n",
    "plt.xlabel('Local Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba0967-9146-4113-97c0-7669b27d68cf",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e746392-4d31-4a85-a692-f410da0dd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df_10['no_of_points'].sum()/126379332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e597104-25b7-4ecf-84f2-e85732bfa49b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b6774-ce40-4182-aaff-e2ee81353e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate local_time based on grt\n",
    "def calculate_local_time(local_date, grt):\n",
    "    start_hour = grt * 3\n",
    "    end_hour = start_hour + 3\n",
    "    return f\"{str(local_date)} {str(start_hour).zfill(2)}:00:00 - {str(end_hour).zfill(2)}:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb4f03-011b-4a71-b2bf-2435250492e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df_10.loc[:, 'local_time'] = combined_df_10.apply(lambda row: calculate_local_time(row['local_date'], row['grt']), axis=1)\n",
    "combined_df_10 = combined_df_10.drop(columns=['grt'])\n",
    "\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05509636-f5c0-4e6b-a268-a54ddb641231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "folder_path = '/home/jovyan/Data/3h_pd3/Clean/'\n",
    "combined_df_10.to_csv(folder_path + 'pd_3h_gh3_in_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7a667-0de7-42db-b6ff-00b6ade18f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4443f38-1026-46ca-b227-4817341e0b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b6c64-3fa5-4211-9c1e-a08fa99c61f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77241e41-d9f5-45bc-ade4-4b3f02837921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295392f-8200-4604-9271-b5d7f4ba1534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6b546-2930-4baf-8415-a49a1d2d995a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2e3a16-20d8-41ec-8549-7db83f38211c",
   "metadata": {},
   "source": [
    "# Delete Below? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb8737-a0fb-404b-b9ed-74b40d2d3ed8",
   "metadata": {},
   "source": [
    "# February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea080452-b180-4216-b8df-b95b080bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200201', '%Y%m%d') AND date_parse('20200228', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_feb.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90546ca-1901-4e54-ae41-6111d3991d60",
   "metadata": {},
   "source": [
    "# March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c747d38-3e35-4e35-b135-7a734c9db27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200301', '%Y%m%d') AND date_parse('20200331', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_mar.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1a670-21d8-4fc3-8c74-ce19ec4f0458",
   "metadata": {},
   "source": [
    "# April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164bf31-504e-4d26-bddf-a5e45b511338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200401', '%Y%m%d') AND date_parse('20200430', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_apr.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561570-050c-4557-9358-897405d2f940",
   "metadata": {},
   "source": [
    "# May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ff01-40a2-4925-9ae7-ea1d92989a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200501', '%Y%m%d') AND date_parse('20200531', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_may.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214da338-6732-459b-aaaf-4398c7772087",
   "metadata": {},
   "source": [
    "# Jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163b5cc-e270-40d6-a2bf-d4fe9f0ffeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200601', '%Y%m%d') AND date_parse('20200630', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jun.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3587-d771-4821-a0f4-15f9cb6d6a69",
   "metadata": {},
   "source": [
    "# July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1f566-367a-4601-bac8-402acb76b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200701', '%Y%m%d') AND date_parse('20200731', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_jul.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d240a-6657-460e-80c4-a392c3a1b48a",
   "metadata": {},
   "source": [
    "# August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1e46a-d995-49dd-9759-38e043f5344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200801', '%Y%m%d') AND date_parse('20200831', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_aug.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ee9fb-1699-45ef-9c18-5184d5588af6",
   "metadata": {},
   "source": [
    "# September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc6fc-2308-4d67-bff3-95c635af0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200901', '%Y%m%d') AND date_parse('20200930', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_set.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391c8c-dadc-4e37-8e11-bdc8d1386c45",
   "metadata": {},
   "source": [
    "# October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57888aba-cb21-4754-90f7-acbbe491da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201001', '%Y%m%d') AND date_parse('20201031', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_oct.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d41ad-f046-4980-9c2c-4cff323200eb",
   "metadata": {},
   "source": [
    "# November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7312d-d666-455f-af6d-1dde05f43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201101', '%Y%m%d') AND date_parse('20201130', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_nov.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d99c18-2bbd-4171-9b09-90922979cce3",
   "metadata": {},
   "source": [
    "# December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850cee5-0a4d-40dd-ae2a-502ea4f65c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201201', '%Y%m%d') AND date_parse('20201231', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_dec.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9dd27-e384-4587-b814-29219529664b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5073-e361-4a26-9933-c0722a60bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
