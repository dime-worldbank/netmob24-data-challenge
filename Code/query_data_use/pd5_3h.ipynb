{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e12420-8683-4154-a7f5-88d98d4528a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from trino.dbapi import connect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b2ec24-24c0-4a8e-acdb-501f288d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL engine class\n",
    "class TrinoEngine():\n",
    "    def __init__(self):\n",
    "        conn = connect(\n",
    "            host=\"localhost\",\n",
    "            port=9090,\n",
    "            catalog=\"cuebiq\"\n",
    "        )\n",
    "        self.cur = conn.cursor()\n",
    "        self.engine = create_engine(\"trino://localhost:9090/cuebiq/\")\n",
    "    \n",
    "    def execute_statement(self, query:str) -> list:\n",
    "        \"\"\"\n",
    "        Create and drop statements.\n",
    "        \"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def read_sql(self, query:str) -> pd.DataFrame: \n",
    "        \"\"\"\n",
    "        Select and insert into operations.\n",
    "        \"\"\"\n",
    "        return pd.read_sql(query, self.engine)\n",
    "\n",
    "    def read_sql_chunked(self, query: str, chunksize: int = 10000):\n",
    "        return pd.read_sql(query, self.engine, chunksize=chunksize)\n",
    "\n",
    "sql_engine = TrinoEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8a785e-275c-4379-ba11-3f3841dfe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the input parameters\n",
    "# country_code = 'CO'\n",
    "# country_code = 'ID'\n",
    "country_code = 'IN'\n",
    "# country_code = 'MX'\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9786e035-b5d2-4cc3-863f-9f8f6a92d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFolder = \"/home/jovyan/Data/3h_pd5/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdf2a8-186b-4da5-8318-da8a9fcd500e",
   "metadata": {},
   "source": [
    "# January to March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a29a9-1081-45ba-8605-8d268a0622e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190101', '%Y%m%d') AND date_parse('20190331', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}13_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fcfb7-5fb9-49b3-b893-c7c5eb087829",
   "metadata": {},
   "source": [
    "# April to June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1c204-95d2-4d95-beec-9ced5c1a5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190401', '%Y%m%d') AND date_parse('20190630', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}46_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce8ce1-df53-4e15-9ddf-180dc37e5f12",
   "metadata": {},
   "source": [
    "# July to September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fd2f6-3ffd-4321-baf6-09fd0638a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20190701', '%Y%m%d') AND date_parse('20190930', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}79_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a928202-df60-412a-9eb9-4633040e224d",
   "metadata": {},
   "source": [
    "# Oct to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9f1ab-e971-4258-93d9-7d2e67b178d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191001', '%Y%m%d') AND date_parse('20191231', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}1012_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ec1a4-f49a-48b3-85a2-e67e8cee547b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bd159-6199-47d5-83e6-289994ef2b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d124bc7-deba-467d-8255-58ba4982b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191001', '%Y%m%d') AND date_parse('20191031', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}10_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03770299-4ef1-42da-9106-7d941fc47531",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191101', '%Y%m%d') AND date_parse('20191130', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}11_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684de393-e855-449e-a6bf-76eb3cd3541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20191201', '%Y%m%d') AND date_parse('20191231', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}12_2019_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c4fb2-18b5-4e47-918d-a0ace8929444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103b0f5-7f37-4a77-92a3-862b2aea91bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a40ea-2ee3-4ebc-b0a3-886dae623501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b711635e-95ff-4a06-9208-902910fc407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the input parameters\n",
    "country_code = 'CO'\n",
    "# country_code = 'ID'\n",
    "# country_code = 'IN'\n",
    "# country_code = 'MX'\n",
    "\n",
    "# Define the input schema and table name\n",
    "schema_name = {'cda': 'cuebiq.paas_cda_pe_v3'}\n",
    "pe_dl_table = f\"{schema_name['cda']}.device_location_uplevelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a77a09-a30c-4f31-ae62-9544c646ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFolder = \"/home/jovyan/Data/3h_pd5/\".format(country_code)\n",
    "Path(pathFolder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907b101a-406a-452b-8397-7ce7572d7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    local_date,\n",
    "    geohash_5\n",
    "FROM\n",
    "    (SELECT \n",
    "        cuebiq_id,\n",
    "        event_zoned_datetime,\n",
    "        geohash_encode(lat, lng, 5) AS geohash_5, \n",
    "        extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt, \n",
    "        DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) AS local_date\n",
    "    FROM {pe_dl_table}\n",
    "    WHERE \n",
    "        country_code = '{country_code}' \n",
    "        AND event_zoned_datetime IS NOT NULL\n",
    "        AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "        AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20200701', '%Y%m%d') AND date_parse('20201231', '%Y%m%d')\n",
    "        AND lat <> 0\n",
    "        AND lng <> 0\n",
    "    )\n",
    "GROUP BY grt, local_date, geohash_5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl = sql_engine.read_sql(query)\n",
    "\n",
    "# Convert 'local_date' to 'yyyymmdd' format\n",
    "pe_dl['local_date'] = pd.to_datetime(pe_dl['local_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# pe_dl\n",
    "\n",
    "fileName = \"{}{}712_2020_3h_agg5.csv\".format(pathFolder,country_code)\n",
    "pe_dl.to_csv(fileName,  sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf56097-a281-453f-9571-e034d93d8500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd21b3-3ba8-4333-aba4-10f989fcd6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d0173-f05c-4087-ad87-f525e55e2381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7c6f8-d181-43b9-8d06-c090b8513eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2e01e-6ae5-4e9a-a205-8c03fcbcf051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be8f6f-b61c-44cb-bbcf-6e41a5f97f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2ed56-461f-44e0-b426-d135cdc0e432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce6251-9ced-4714-b994-7cf9e96b190e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7e4cbc-1fb5-4cbe-a585-ec24e519b1d6",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad09dfa-7697-4257-965f-ba8a177c4b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0b47c7-ddfb-4ad9-9621-470507619974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d753647-235c-4a37-894d-95599d525a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/Data/3h_pd5/CO13_2020_3h_agg5.csv',\n",
       " '/home/jovyan/Data/3h_pd5/CO712_2020_3h_agg5.csv',\n",
       " '/home/jovyan/Data/3h_pd5/CO46_2020_3h_agg5.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_pattern = '/home/jovyan/Data/3h_pd5/CO*_2020_3h_agg5.csv'\n",
    "file_list = glob.glob(path_pattern)\n",
    "file_sub_list = [path for path in file_list]\n",
    "file_sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212fed81-ed44-46f4-9a3a-3db20076366e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d4jzs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2g4v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d2gzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2d2x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d347b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815257</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3h0w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815258</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2g55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815259</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2kqb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815260</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3gbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815261</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3k7v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6815262 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 397                  40    3    20200119     d4jzs\n",
       "1                 217                  40    5    20200118     d2g4v\n",
       "2                 351                  47    4    20200119     d2gzd\n",
       "3                 439                  88    7    20200118     d2d2x\n",
       "4                1266                 263    2    20200119     d347b\n",
       "...               ...                 ...  ...         ...       ...\n",
       "6815257             6                   1    6    20200505     d3h0w\n",
       "6815258             7                   1    7    20200505     d2g55\n",
       "6815259            11                   1    7    20200505     d2kqb\n",
       "6815260             1                   1    6    20200505     d3gbh\n",
       "6815261             1                   1    4    20200505     d3k7v\n",
       "\n",
       "[6815262 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448f1d8-1b8f-4c2f-9998-428eef1f964e",
   "metadata": {},
   "source": [
    "## Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21bf73c-0b2d-4fe2-8cae-4dbf43328238",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d4jzs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2g4v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d2gzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2d2x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d347b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815257</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3h0w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815258</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2g55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815259</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2kqb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815260</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3gbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815261</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d3k7v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6815262 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 397                  40    3    20200119     d4jzs\n",
       "1                 217                  40    5    20200118     d2g4v\n",
       "2                 351                  47    4    20200119     d2gzd\n",
       "3                 439                  88    7    20200118     d2d2x\n",
       "4                1266                 263    2    20200119     d347b\n",
       "...               ...                 ...  ...         ...       ...\n",
       "6815257             6                   1    6    20200505     d3h0w\n",
       "6815258             7                   1    7    20200505     d2g55\n",
       "6815259            11                   1    7    20200505     d2kqb\n",
       "6815260             1                   1    6    20200505     d3gbh\n",
       "6815261             1                   1    4    20200505     d3k7v\n",
       "\n",
       "[6815262 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['geohash_5'] = combined_df['geohash_5'].astype(str)\n",
    "combined_df['no_of_points'] = combined_df['no_of_points'].astype(int)\n",
    "combined_df['no_of_unique_users'] = combined_df['no_of_unique_users'].astype(int)\n",
    "combined_df['local_date'] = combined_df['local_date'].astype(int)\n",
    "\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fe3ec-2018-4204-921d-0ab2aa4d2028",
   "metadata": {},
   "source": [
    "## Check missing date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503d3b85-9904-46fc-9c29-59caf7b2b3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_count = combined_df[\"local_date\"].unique()\n",
    "all_dates = pd.date_range(start='2020-01-01', end='2020-12-31').strftime('%Y%m%d').astype(int)\n",
    "all_dates = np.array(all_dates)\n",
    "missing_dates = np.setdiff1d(all_dates, unique_values_count)\n",
    "\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839eda4-7591-4c6c-961c-949ef9179ac4",
   "metadata": {},
   "source": [
    "## Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690bffcd-c0b4-4ad8-858e-fd5be3ed5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>grt</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d4jzs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2g4v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d2gzd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2d2x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d347b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785743</th>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>20200426</td>\n",
       "      <td>d2gk0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793225</th>\n",
       "      <td>73</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>20200610</td>\n",
       "      <td>d2g1y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793319</th>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>20200503</td>\n",
       "      <td>d2f4n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795233</th>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2g7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795238</th>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>20200625</td>\n",
       "      <td>d347j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616967 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         no_of_points  no_of_unique_users  grt  local_date geohash_5\n",
       "0                 397                  40    3    20200119     d4jzs\n",
       "1                 217                  40    5    20200118     d2g4v\n",
       "2                 351                  47    4    20200119     d2gzd\n",
       "3                 439                  88    7    20200118     d2d2x\n",
       "4                1266                 263    2    20200119     d347b\n",
       "...               ...                 ...  ...         ...       ...\n",
       "6785743            87                  11    5    20200426     d2gk0\n",
       "6793225            73                  20    6    20200610     d2g1y\n",
       "6793319            51                  11    2    20200503     d2f4n\n",
       "6795233            68                  12    6    20200505     d2g7e\n",
       "6795238            56                  11    7    20200625     d347j\n",
       "\n",
       "[616967 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_10 = combined_df[combined_df['no_of_unique_users'] >= 10]\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549e44e-d718-4286-9500-a6cb10587537",
   "metadata": {},
   "source": [
    "## Check with figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a7c34-243b-40b4-9d79-a4b3462a2aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebee9c-eebf-4e36-a869-b70695137122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d4b29-b335-4ff4-b7ee-cc997485d5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e2e9076-c0b1-4aaa-b96a-04dc25189933",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5786cdb-b2ae-4652-8eb1-1b3e1aee0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate local_time based on grt\n",
    "def calculate_local_time(local_date, grt):\n",
    "    start_hour = grt * 3\n",
    "    end_hour = start_hour + 3\n",
    "    return f\"{str(local_date)} {str(start_hour).zfill(2)}:00:00 - {str(end_hour).zfill(2)}:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de7652a-fdd5-4bec-9b6e-273f3ee75546",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328/2217125973.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df_10.loc[:, 'local_time'] = combined_df_10.apply(lambda row: calculate_local_time(row['local_date'], row['grt']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_points</th>\n",
       "      <th>no_of_unique_users</th>\n",
       "      <th>local_date</th>\n",
       "      <th>geohash_5</th>\n",
       "      <th>local_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>40</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d4jzs</td>\n",
       "      <td>20200119 09:00:00 - 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>40</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2g4v</td>\n",
       "      <td>20200118 15:00:00 - 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351</td>\n",
       "      <td>47</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d2gzd</td>\n",
       "      <td>20200119 12:00:00 - 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439</td>\n",
       "      <td>88</td>\n",
       "      <td>20200118</td>\n",
       "      <td>d2d2x</td>\n",
       "      <td>20200118 21:00:00 - 24:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266</td>\n",
       "      <td>263</td>\n",
       "      <td>20200119</td>\n",
       "      <td>d347b</td>\n",
       "      <td>20200119 06:00:00 - 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785743</th>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>20200426</td>\n",
       "      <td>d2gk0</td>\n",
       "      <td>20200426 15:00:00 - 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793225</th>\n",
       "      <td>73</td>\n",
       "      <td>20</td>\n",
       "      <td>20200610</td>\n",
       "      <td>d2g1y</td>\n",
       "      <td>20200610 18:00:00 - 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793319</th>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>20200503</td>\n",
       "      <td>d2f4n</td>\n",
       "      <td>20200503 06:00:00 - 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795233</th>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>20200505</td>\n",
       "      <td>d2g7e</td>\n",
       "      <td>20200505 18:00:00 - 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795238</th>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>20200625</td>\n",
       "      <td>d347j</td>\n",
       "      <td>20200625 21:00:00 - 24:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616967 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         no_of_points  no_of_unique_users  local_date geohash_5  \\\n",
       "0                 397                  40    20200119     d4jzs   \n",
       "1                 217                  40    20200118     d2g4v   \n",
       "2                 351                  47    20200119     d2gzd   \n",
       "3                 439                  88    20200118     d2d2x   \n",
       "4                1266                 263    20200119     d347b   \n",
       "...               ...                 ...         ...       ...   \n",
       "6785743            87                  11    20200426     d2gk0   \n",
       "6793225            73                  20    20200610     d2g1y   \n",
       "6793319            51                  11    20200503     d2f4n   \n",
       "6795233            68                  12    20200505     d2g7e   \n",
       "6795238            56                  11    20200625     d347j   \n",
       "\n",
       "                           local_time  \n",
       "0        20200119 09:00:00 - 12:00:00  \n",
       "1        20200118 15:00:00 - 18:00:00  \n",
       "2        20200119 12:00:00 - 15:00:00  \n",
       "3        20200118 21:00:00 - 24:00:00  \n",
       "4        20200119 06:00:00 - 09:00:00  \n",
       "...                               ...  \n",
       "6785743  20200426 15:00:00 - 18:00:00  \n",
       "6793225  20200610 18:00:00 - 21:00:00  \n",
       "6793319  20200503 06:00:00 - 09:00:00  \n",
       "6795233  20200505 18:00:00 - 21:00:00  \n",
       "6795238  20200625 21:00:00 - 24:00:00  \n",
       "\n",
       "[616967 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_10.loc[:, 'local_time'] = combined_df_10.apply(lambda row: calculate_local_time(row['local_date'], row['grt']), axis=1)\n",
    "combined_df_10 = combined_df_10.drop(columns=['grt'])\n",
    "\n",
    "combined_df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c783cdee-f3f8-48f6-8020-7eb8f0f2df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "folder_path = '/home/jovyan/Data/3h_pd5/Clean/'\n",
    "combined_df_10.to_csv(folder_path + 'pd_3h_gh5_co_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52662c72-6a81-4afa-8988-b925fb7cf0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1da0c5-474e-46fe-8a88-9ce60d2436f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60754415-e11a-466b-9d7b-45f90bf8c43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7312d-d666-455f-af6d-1dde05f43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201101', '%Y%m%d') AND date_parse('20201130', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_nov.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850cee5-0a4d-40dd-ae2a-502ea4f65c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS no_of_points,\n",
    "    COUNT(DISTINCT(cuebiq_id)) AS no_of_unique_users,\n",
    "    grt,\n",
    "    day,\n",
    "    month,\n",
    "    geohash5\n",
    "FROM\n",
    "(SELECT \n",
    "    cuebiq_id,\n",
    "    event_zoned_datetime,\n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  hour,\n",
    "    extract(DAY FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  day,\n",
    "    extract(MONTH FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))  month,\n",
    "    geohash_encode(lat, lng, 5) AS geohash5, \n",
    "    extract(HOUR FROM date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))/3  grt\n",
    "FROM {pe_dl_table}\n",
    "WHERE \n",
    "    country_code = '{country_code}' \n",
    "    AND event_zoned_datetime IS NOT NULL\n",
    "    AND TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s')) IS NOT NULL\n",
    "    AND DATE(TRY(date_parse(substr(event_zoned_datetime, 1, 19), '%Y-%m-%dT%H:%i:%s'))) BETWEEN date_parse('20201201', '%Y%m%d') AND date_parse('20201231', '%Y%m%d') \n",
    ")\n",
    "GROUP BY grt, day, month, geohash5\n",
    "\"\"\"\n",
    "\n",
    "pe_dl_table_gen = sql_engine.read_sql(query)\n",
    "fileName = \"{}{}_daily_agg5_hour_dec.csv\".format(pathFolder,country_code)\n",
    "pe_dl_table_gen.sort_values(['grt','day'], inplace=True)\n",
    "pe_dl_table_gen.to_csv(fileName,  sep=',', index=False)\n",
    "kanonimization (fileName,popDensity_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9dd27-e384-4587-b814-29219529664b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5073-e361-4a26-9933-c0722a60bbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
